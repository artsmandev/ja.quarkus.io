# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2021-08-23 02:16+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. This guide is maintained in the main Quarkus repository
#. and pull requests should be submitted there:
#. https://github.com/quarkusio/quarkus/tree/main/docs/src/main/asciidoc
#. type: Title =
#: upstream/_versions/main/guides/kafka.adoc:6
#, no-wrap
msgid "Apache Kafka Reference Guide"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:16
#, fuzzy
#| msgid "This guide demonstrates how your Quarkus application can utilize SmallRye Reactive Messaging to interact with Apache Kafka."
msgid "This reference guide demonstrates how your Quarkus application can utilize SmallRye Reactive Messaging to interact with Apache Kafka."
msgstr "このガイドでは、Quarkus アプリケーションが SmallRye Reactive Messaging を利用して Apache Kafka とやりとりする仕組みを説明します。"

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:17
#, fuzzy, no-wrap
#| msgid "Solution"
msgid "Introduction"
msgstr "ソリューション"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:22
msgid "https://kafka.apache.org[Apache Kafka] is a popular open-source distributed event streaming platform.  It is used commonly for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.  Similar to a message queue, or an enterprise messaging platform, it lets you:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:24
#, no-wrap
msgid "*publish* (write) and *subscribe* to (read) streams of events, called _records_.\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:25
#, no-wrap
msgid "*store* streams of records durably and reliably inside _topics_.\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:26
#, no-wrap
msgid "*process* streams of records as they occur or retrospectively.\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:28
msgid "And all this functionality is provided in a distributed, highly scalable, elastic, fault-tolerant, and secure manner."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:29
#, no-wrap
msgid "Quarkus Extension for Apache Kafka"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:33
msgid "Quarkus provides support for Apache Kafka through https://smallrye.io/smallrye-reactive-messaging/[SmallRye Reactive Messaging] framework.  Based on Eclipse MicroProfile Reactive Messaging specification 2.0, it proposes a flexible programming model bridging CDI and event-driven."
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:38
msgid "This guide provides an in-depth look on Apache Kafka and SmallRye Reactive Messaging framework.  For a quick start take a look at xref:kafka-reactive-getting-started.adoc[Getting Started to SmallRye Reactive Messaging with Apache Kafka]."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:41
#, fuzzy
#| msgid "If you already have your Quarkus project configured, you can add the `smallrye-reactive-messaging-kafka` extension to your project by running the following command in your project base directory:"
msgid "You can add the `smallrye-reactive-messaging-kafka` extensions to your project by running the following command in your project base directory:"
msgstr "すでにQuarkusプロジェクトが設定されている場合は、プロジェクトのベースディレクトリーで以下のコマンドを実行することで、プロジェクトに `smallrye-reactive-messaging-kafka` エクステンションを追加することができます。"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:45
#, no-wrap
msgid "./mvnw quarkus:add-extension -Dextensions=\"smallrye-reactive-messaging-kafka\"\n"
msgstr "./mvnw quarkus:add-extension -Dextensions=\"smallrye-reactive-messaging-kafka\"\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:48
msgid "This will add the following to your `pom.xml`:"
msgstr "これにより、 `pom.xml` に以下が追加されます。"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:55
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-smallrye-reactive-messaging-kafka</artifactId>\n"
"</dependency>\n"
msgstr ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-smallrye-reactive-messaging-kafka</artifactId>\n"
"</dependency>\n"

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:57
#, no-wrap
msgid "Configuring Smallrye Kafka Connector"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:60
msgid "Because Smallrye Reactive Messaging framework supports different messaging backends like Apache Kafka, AMQP, Apache Camel, JMS, MQTT, etc., it employs a generic vocabulary:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:62
msgid "Applications send and receive *messages*. A message wraps a _payload_ and can be extended with some _metadata_. With the Kafka connector, a _message_ corresponds to a Kafka _record_."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:63
msgid "Messages transit on *channels*. Application components connect to channels to publish and consume messages. The Kafka connector maps _channels_ to Kafka _topics_."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:64
msgid "Channels are connected to message backends using *connectors*. Connectors are configured to map incoming messages to a specific channel (consumed by the application) and collect outgoing messages sent to a specific channel. Each connector is dedicated to a specific messaging technology. For example, the connector dealing with Kafka is named `smallrye-kafka`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:66
msgid "A minimal configuration for the Kafka connector with an incoming channel looks like the following:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:71
#, no-wrap
msgid ""
"%prod.kafka.bootstrap.servers=kafka:9092 <1>\n"
"mp.messaging.incoming.prices.connector=smallrye-kafka <2>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:76
msgid "Configure the broker location for the production profile. You can configure it globally or per channel using `mp.messaging.incoming.$channel.bootstrap.servers` property.  In dev mode and when running tests, link:kafka-dev-services[Dev Services for Kafka] automatically starts a Kafka broker.  When not provided this property defaults to `localhost:9092`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:77
msgid "Configure the connector to manage the prices channel. By default the topic name is same as the channel name. You can configure the topic attribute to override it."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:79
msgid "The `%prod` prefix indicates that the property is only used when the application runs in prod mode (so not in dev or test). Refer to the xref:config-reference.adoc#profiles[Profile documentation] for further details."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:80
#, no-wrap
msgid "Receiving messages from Kafka"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:83
msgid "Continuing from the previous minimal configuration, your Quarkus application can receive message payload directly:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:87
#: upstream/_versions/main/guides/kafka.adoc:1717
#: upstream/_versions/main/guides/kafka.adoc:1798
#, fuzzy, no-wrap
#| msgid "`org.eclipse.microprofile.reactive.messaging.Emitter`"
msgid "import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
msgstr "`org.eclipse.microprofile.reactive.messaging.Emitter`"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:89
#: upstream/_versions/main/guides/kafka.adoc:868
#: upstream/_versions/main/guides/kafka.adoc:915
#: upstream/_versions/main/guides/kafka.adoc:938
#: upstream/_versions/main/guides/kafka.adoc:1078
#: upstream/_versions/main/guides/kafka.adoc:1796
#, no-wrap
msgid "import javax.enterprise.context.ApplicationScoped;\n"
msgstr "import javax.enterprise.context.ApplicationScoped;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:92
#, fuzzy, no-wrap
#| msgid ""
#| "@ApplicationScoped\n"
#| "public class PriceStorage {\n"
msgid ""
"@ApplicationScoped\n"
"public class PriceConsumer {\n"
msgstr ""
"@ApplicationScoped\n"
"public class PriceStorage {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:97
#, fuzzy, no-wrap
#| msgid ""
#| "    @POST\n"
#| "    @Consumes(MediaType.TEXT_PLAIN)\n"
#| "    public void addPrice(Double price) {\n"
#| "        priceEmitter.send(price);\n"
#| "    }\n"
#| "}\n"
msgid ""
"    @Incoming(\"prices\")\n"
"    public void consume(double price) {\n"
"        // process your price.\n"
"    }\n"
msgstr ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public void addPrice(Double price) {\n"
"        priceEmitter.send(price);\n"
"    }\n"
"}\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:99
#: upstream/_versions/main/guides/kafka.adoc:244
#: upstream/_versions/main/guides/kafka.adoc:509
#: upstream/_versions/main/guides/kafka.adoc:535
#: upstream/_versions/main/guides/kafka.adoc:616
#: upstream/_versions/main/guides/kafka.adoc:928
#: upstream/_versions/main/guides/kafka.adoc:956
#: upstream/_versions/main/guides/kafka.adoc:1040
#: upstream/_versions/main/guides/kafka.adoc:1097
#: upstream/_versions/main/guides/kafka.adoc:1510
#: upstream/_versions/main/guides/kafka.adoc:1705
#: upstream/_versions/main/guides/kafka.adoc:1786
#: upstream/_versions/main/guides/kafka.adoc:1814
#, no-wrap
msgid "}\n"
msgstr "}\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:102
msgid "There are several other ways your application can consume incoming messages:"
msgstr ""

#. type: Block title
#: upstream/_versions/main/guides/kafka.adoc:103
#, no-wrap
msgid "Message"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:115
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public CompletionStage<Void> consume(Message<Double> msg) {\n"
"    // access record metadata\n"
"    var metadata = msg.getMetadata(IncomingKafkaRecordMetadata.class).orElseThrow();\n"
"    // process the message payload.\n"
"    double price = msg.getPayload();\n"
"    // Acknowledge the incoming message (commit the offset)\n"
"    return msg.ack();\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:119
msgid "The `Message` type lets the consuming method access the incoming message metadata and handle the acknowledgment manually.  We'll explore different acknowledgment strategies in <<commit-strategies>>."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:121
msgid "If you want to access the Kafka record objects directly, use:"
msgstr ""

#. type: Block title
#: upstream/_versions/main/guides/kafka.adoc:122
#, no-wrap
msgid "ConsumerRecord"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:133
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public void consume(ConsumerRecord<String, Double> record) {\n"
"    String key = record.key(); // Can be `null` if the incoming record has no key\n"
"    String value = record.value(); // Can be `null` if the incoming record has no value\n"
"    String topic = record.topic();\n"
"    int partition = record.partition();\n"
"    // ...\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:137
msgid "`ConsumerRecord` is provided by the underlying Kafka client and can be injected directly to the consumer method.  Another simpler approach consists in using `Record`:"
msgstr ""

#. type: Block title
#: upstream/_versions/main/guides/kafka.adoc:138
#, no-wrap
msgid "Record"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:146
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public void consume(Record<String, Double> record) {\n"
"    String key = record.key(); // Can be `null` if the incoming record has no key\n"
"    String value = record.value(); // Can be `null` if the incoming record has no value\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:149
msgid "`Record` is a simple wrapper around key and payload of the incoming Kafka record."
msgstr ""

#. type: Block title
#: upstream/_versions/main/guides/kafka.adoc:150
#, no-wrap
msgid "@Channel"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:153
msgid "Alternatively, your application can inject a `Multi` in your bean and subscribe to its events as the following example:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:158
#, fuzzy, no-wrap
#| msgid ""
#| "import io.smallrye.mutiny.Multi;\n"
#| "import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
msgid ""
"import io.smallrye.mutiny.Multi;\n"
"import io.smallrye.reactive.messaging.annotations.Channel;\n"
msgstr ""
"import io.smallrye.mutiny.Multi;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:165
#, no-wrap
msgid ""
"import javax.inject.Inject;\n"
"import javax.ws.rs.GET;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.Produces;\n"
"import javax.ws.rs.core.MediaType;\n"
"import org.jboss.resteasy.annotations.SseElementType;\n"
msgstr ""
"import javax.inject.Inject;\n"
"import javax.ws.rs.GET;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.Produces;\n"
"import javax.ws.rs.core.MediaType;\n"
"import org.jboss.resteasy.annotations.SseElementType;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:168
#: upstream/_versions/main/guides/kafka.adoc:697
#: upstream/_versions/main/guides/kafka.adoc:742
#: upstream/_versions/main/guides/kafka.adoc:778
#, no-wrap
msgid ""
"@Path(\"/prices\")\n"
"public class PriceResource {\n"
msgstr ""
"@Path(\"/prices\")\n"
"public class PriceResource {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:172
#, fuzzy, no-wrap
#| msgid "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"
msgid ""
"    @Inject\n"
"    @Channel(\"prices\")\n"
"    Multi<Double> prices;\n"
msgstr "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:181
#, fuzzy, no-wrap
#| msgid ""
#| "    @GET\n"
#| "    @Path(\"/stream\")\n"
#| "    @Produces(MediaType.SERVER_SENT_EVENTS) // <2>\n"
#| "    @SseElementType(\"text/plain\") // <3>\n"
#| "    public Publisher<Double> stream() { // <4>\n"
#| "        return prices;\n"
#| "    }\n"
#| "}\n"
msgid ""
"    @GET\n"
"    @Path(\"/prices\")\n"
"    @Produces(MediaType.SERVER_SENT_EVENTS)\n"
"    @SseElementType(\"text/plain\")\n"
"    public Multi<Double> stream() {\n"
"        return prices;\n"
"    }\n"
"}\n"
msgstr ""
"    @GET\n"
"    @Path(\"/stream\")\n"
"    @Produces(MediaType.SERVER_SENT_EVENTS) // <2>\n"
"    @SseElementType(\"text/plain\") // <3>\n"
"    public Publisher<Double> stream() { // <4>\n"
"        return prices;\n"
"    }\n"
"}\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:185
msgid "This is a good example of how to integrate a Kafka consumer with another downstream, in this example exposing it as a Server-Sent Events endpoint."
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:191
msgid "When consuming messages with `@Channel`, the application code is responsible for the subscription.  In the example above, RESTEasy endpoint handles that for you."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:194
msgid "Following types can be injected as channels:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:198
#, fuzzy, no-wrap
#| msgid "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"
msgid "@Inject @Channel(\"prices\") Multi<Double> streamOfPayloads;\n"
msgstr "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:200
#, fuzzy, no-wrap
#| msgid "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"
msgid "@Inject @Channel(\"prices\") Multi<Message<Double>> streamOfMessages;\n"
msgstr "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:202
#, fuzzy, no-wrap
#| msgid "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"
msgid "@Inject @Channel(\"prices\") Publisher<Double> publisherOfPayloads;\n"
msgstr "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:204
#, fuzzy, no-wrap
#| msgid "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"
msgid "@Inject @Channel(\"prices\") Publisher<Message<Double>> publisherOfMessages;\n"
msgstr "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:209
msgid "As with the previous `Message` example, if your injected channel receives payloads (`Multi<T>`), it acknowledges the message automatically, and support multiple subscribers.  If you injected channel receives Message (`Multi<Message<T>>`), you will be responsible for the acknowledgment and broadcasting.  We will explore sending broadcast messages in <<broadcasting-messages-on-multiple-consumers>>."
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:214
msgid "Injecting `@Channel(\"prices\")` or having `@Incoming(\"prices\")` does not automatically configure the application to consume messages from Kafka.  You need to configure an inbound connector with `mp.messaging.incoming.prices\\...` or have an `@Outgoing(\"prices\")` method somewhere in your application (in which case, `prices` will be an in-memory channel)."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:216
#, no-wrap
msgid "Blocking processing"
msgstr "ブロッキング処理"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:220
#, fuzzy
#| msgid "You often need to combine Reactive Messaging with blocking processing such as database interactions.  For this, you need to use the `@Blocking` annotation indicating that the processing is _blocking_ and cannot be run on the caller thread."
msgid "You often need to combine Reactive Messaging with blocking processing such as database interactions.  For this, you need to use the `@Blocking` annotation indicating that the processing is _blocking_ and should not be run on the caller thread."
msgstr "Reactive Messaging とデータベースインタラクションなどのブロッキング処理を組み合わせる必要がある状況は少なくありません。そのためには、処理が _ブロックしていて_ 呼び出し元のスレッドで実行できないこと示している `@Blocking` アノテーションを使用する必要があります。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:222
msgid "For example, The following code illustrates how you can store incoming payloads to a database using Hibernate with Panache:"
msgstr "例えば、以下のコードは、Hibernate with Panacheを 使用してデータベースに受信ペイロードを格納する方法を示しています。"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:227
#, no-wrap
msgid ""
"import io.smallrye.reactive.messaging.annotations.Blocking;\n"
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
msgstr ""
"import io.smallrye.reactive.messaging.annotations.Blocking;\n"
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:230
#: upstream/_versions/main/guides/kafka.adoc:1715
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.transaction.Transactional;\n"
msgstr ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.transaction.Transactional;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:233
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class PriceStorage {\n"
msgstr ""
"@ApplicationScoped\n"
"public class PriceStorage {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:242
#, no-wrap
msgid ""
"    @Incoming(\"prices\")\n"
"    @Blocking\n"
"    @Transactional\n"
"    public void store(int priceInUsd) {\n"
"        Price price = new Price();\n"
"        price.value = priceInUsd;\n"
"        price.persist();\n"
"    }\n"
msgstr ""
"    @Incoming(\"prices\")\n"
"    @Blocking\n"
"    @Transactional\n"
"    public void store(int priceInUsd) {\n"
"        Price price = new Price();\n"
"        price.value = priceInUsd;\n"
"        price.persist();\n"
"    }\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:247
msgid "The complete example is available in the `kafka-panache-quickstart` {quickstarts-tree-url}/kafka-panache-quickstart[directory]."
msgstr "完全な例は `kafka-panache-quickstart` {quickstarts-tree-url}/kafka-panache-quickstart[ディレクトリー] にあります。"

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:251
msgid "There are 2 `@Blocking` annotations:"
msgstr "`@Blocking` アノテーションは 2 つあります。"

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:253
msgid "`io.smallrye.reactive.messaging.annotations.Blocking`"
msgstr "`io.smallrye.reactive.messaging.annotations.Blocking`"

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:254
msgid "`io.smallrye.common.annotation.Blocking`"
msgstr "`io.smallrye.common.annotation.Blocking`"

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:259
#, fuzzy
#| msgid "They have the same effect.  Thus, you can use both.  The first one provides more fine-grain tuning such as the worker pool to use and whether it preserves the order.  The second one, used in also with other reactive features of Quarkus, uses the default worker pool and preserves the order."
msgid "They have the same effect.  Thus, you can use both.  The first one provides more fine-grained tuning such as the worker pool to use and whether it preserves the order.  The second one, used also with other reactive features of Quarkus, uses the default worker pool and preserves the order."
msgstr "効果はどちらも同じです。したがって、両方を使うことができます。最初のものは、使用するワーカープールや順序を保持するかどうかなど、より細かい調整が可能です。2 番目のものは、Quarkus の他のリアクティブ機能でも使用され、デフォルトのワーカープールを使用し、順序を保持します。"

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:261
#, no-wrap
msgid "Acknowledgment Strategies"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:269
msgid "All messages received by a consumer must be acknowledged.  In the absence of acknowledgment, the processing is considered in error.  If the consumer method receives a `Record` or a payload, the message will be acked on method return, also known as `Strategy.POST_PROCESSING`.  If the consumer method returns another reactive stream or `CompletionStage`, the message will be acked when the downstream message is acked.  You can override the default behavior to ack the message on arrival (`Strategy.PRE_PROCESSING`), or do not ack the message at all (`Strategy.NONE`) on the consumer method as in the following example:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:277
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"@Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING)\n"
"public void process(double price) {\n"
"    // process price\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:281
msgid "If the consumer method receives a `Message`, the acknowledgment strategy is `Strategy.MANUAL` and the consumer method is in charge of ack/nack the message."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:289
#, fuzzy, no-wrap
#| msgid ""
#| "    @POST\n"
#| "    @Consumes(MediaType.TEXT_PLAIN)\n"
#| "    public void addPrice(Double price) {\n"
#| "        priceEmitter.send(price);\n"
#| "    }\n"
#| "}\n"
msgid ""
"@Incoming(\"prices\")\n"
"public CompletionStage<Void> process(Message<Double> msg) {\n"
"    // process price\n"
"    return msg.ack();\n"
"}\n"
msgstr ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public void addPrice(Double price) {\n"
"        priceEmitter.send(price);\n"
"    }\n"
"}\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:292
msgid "As mentioned above, the method can also override the acknowledgment strategy to `PRE_PROCESSING` or `NONE`."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:294
#, fuzzy, no-wrap
#| msgid "*commit-strategy*"
msgid "Commit Strategies"
msgstr "*commit-strategy*"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:300
msgid "When a message produced from a Kafka record is acknowledged, the connector invokes a commit strategy.  These strategies decide when the consumer offset for a specific topic/partition is committed.  Committing an offset indicates that all previous records have been processed.  It is also the position where the application would restart the processing after a crash recovery or a restart."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:303
msgid "Committing every offset has performance penalties as Kafka offset management can be slow.  However, not committing the offset often enough may lead to message duplication if the application crashes between two commits."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:305
msgid "The Kafka connector supports three strategies:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:314
msgid "`throttled` keeps track of received messages and commits an offset of the latest acked message in sequence (meaning, all previous messages were also acked).  This strategy guarantees at-least-once delivery even if the channel performs asynchronous processing.  The connector tracks the received records and periodically (period specified by `auto.commit.interval.ms`, default: 5000 ms) commits the highest consecutive offset.  The connector will be marked as unhealthy if a message associated with a record is not acknowledged in `throttled.unprocessed-record-max-age.ms` (default: 60000 ms).  Indeed, this strategy cannot commit the offset as soon as a single record processing fails (see <<error-handling>> to configure what happens on failing processing).  If `throttled.unprocessed-record-max-age.ms` is set to less than or equal to `0`, it does not perform any health check verification.  Such a setting might lead to running out of memory if there are \"poison pill\" messages (that are never acked).  This strategy is the default if `enable.auto.commit` is not explicitly set to true."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:318
msgid "`latest` commits the record offset received by the Kafka consumer as soon as the associated message is acknowledged (if the offset is higher than the previously committed offset).  This strategy provides at-least-once delivery if the channel processes the message without performing any asynchronous processing.  This strategy should not be used in high load environment, as offset commit is expensive. However, it reduces the risk of duplicates."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:323
msgid "`ignore` performs no commit. This strategy is the default strategy when the consumer is explicitly configured with `enable.auto.commit` to true.  It delegates the offset commit to the underlying Kafka client.  This strategy provides at-least-once delivery if the channel processes the message without performing any asynchronous operations and when `enable.auto.commit` is set to true.  However, if the processing failed between two commits, messages received after the commit and before the failure will be re-processed."
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:328
msgid "The Kafka connector disables the Kafka auto commit when it is not explicitly enabled. This behavior differs from the traditional Kafka consumer.  If high throughput is important for you, and you are not limited by the downstream, we recommend to either:"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:330
msgid "use the `throttled` policy,"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:331
msgid "or set `enable.auto.commit` to true and annotate the consuming method with `@Acknowledgment(Acknowledgment.Strategy.NONE)`."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:334
#, no-wrap
msgid "Error Handling Strategies"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:337
msgid "If a message produced from a Kafka record is nacked, a failure strategy is applied. The Kafka connector supports three strategies:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:339
msgid "`fail`: fail the application, no more records will be processed (default strategy). The offset of the record that has not been processed correctly is not committed."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:340
msgid "`ignore`: the failure is logged, but the processing continue. The offset of the record that has not been processed correctly is committed."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:341
msgid "`dead-letter-queue`: the offset of the record that has not been processed correctly is committed, but the record is written to a Kafka dead letter topic."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:343
msgid "The strategy is selected using the `failure-strategy` attribute."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:345
msgid "In the case of `dead-letter-queue`, you can configure the following attributes:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:347
msgid "`dead-letter-queue.topic`: the topic to use to write the records not processed correctly, default is `dead-letter-topic-$channel`, with `$channel` being the name of the channel."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:348
msgid "`dead-letter-queue.key.serializer`: the serializer used to write the record key on the dead letter queue. By default, it deduces the serializer from the key deserializer."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:349
msgid "`dead-letter-queue.value.serializer`: the serializer used to write the record value on the dead letter queue. By default, it deduces the serializer from the value deserializer."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:351
msgid "The record written on the dead letter queue contains a set of additional headers about the original record:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:353
#, no-wrap
msgid "*dead-letter-reason*: the reason of the failure\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:354
#, no-wrap
msgid "*dead-letter-cause*: the cause of the failure if any\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:355
#, no-wrap
msgid "*dead-letter-topic*: the original topic of the record\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:356
#, no-wrap
msgid "*dead-letter-partition*: the original partition of the record (integer mapped to String)\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:357
#, no-wrap
msgid "*dead-letter-offset*: the original offset of the record (long mapped to String)\n"
msgstr ""

#. type: Title ====
#: upstream/_versions/main/guides/kafka.adoc:358
#, fuzzy, no-wrap
#| msgid "Blocking processing"
msgid "Retrying processing"
msgstr "ブロッキング処理"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:361
msgid "You can combine Reactive Messaging with https://github.com/smallrye/smallrye-fault-tolerance[SmallRye Fault Tolerance], and retry processing if it failed:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:369
#, no-wrap
msgid ""
"@Incoming(\"kafka\")\n"
"@Retry(delay = 10, maxRetries = 5)\n"
"public void consume(String v) {\n"
"   // ... retry if this method throws an exception\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:372
msgid "You can configure the delay, the number of retries, the jitter, etc."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:374
msgid "If your method returns a `Uni` or `CompletionStage`, you need to add the `@NonBlocking` annotation:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:383
#, no-wrap
msgid ""
"@Incoming(\"kafka\")\n"
"@Retry(delay = 10, maxRetries = 5)\n"
"@NonBlocking\n"
"public Uni<String> consume(String v) {\n"
"   // ... retry if this method throws an exception or the returned Uni produce a failure\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:388
msgid "The `@NonBlocking` annotation is only required with SmallRye Fault Tolerance 5.1.0 and earlier.  Starting with SmallRye Fault Tolerance 5.2.0 (available since Quarkus 2.1.0.Final), it is not necessary.  See https://smallrye.io/docs/smallrye-fault-tolerance/5.2.0/usage/extra.html#_non_compatible_mode[SmallRye Fault Tolerance documentation] for more information."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:392
msgid "The incoming messages are acknowledged only once the processing completes successfully.  So, it commits the offset after the successful processing.  If the processing still fails, even after all retries, the message is _nacked_ and the failure strategy is applied."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:393
#, no-wrap
msgid "Consumer Groups"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:400
msgid "In Kafka, a consumer group is a set of consumers which cooperate to consume data from a topic.  A topic is divided into a set of partitions.  The partitions of a topic are assigned among the consumers in the group, effectively allowing to scale consumption throughput.  Note that each partition is assigned to a single consumer from a group.  However, a consumer can be assigned multiple partitions if the number of partitions is greater than the number of consumer in the group."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:402
msgid "Let's explore briefly different producer/consumer patterns and how to implement them using Quarkus:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:404
#, no-wrap
msgid "*Single consumer thread inside a consumer group*\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:408
msgid "This is the default behavior of an application subscribing to a Kafka topic: Each Kafka connector will create a single consumer thread and place it inside a single consumer group.  Consumer group id defaults to the application name as set by the `quarkus.application.name` configuration property.  It can also be set using the `kafka.group.id` property."
msgstr ""

#. type: Named 'alt' AttributeList argument for macro 'image'
#: upstream/_versions/main/guides/kafka.adoc:409
#: upstream/_versions/main/guides/kafka.adoc:417
#: upstream/_versions/main/guides/kafka.adoc:424
#: upstream/_versions/main/guides/kafka.adoc:432
#, fuzzy, no-wrap
#| msgid "Architecture"
msgid "Architecture,"
msgstr "アーキテクチャ"

#. type: Target for macro image
#: upstream/_versions/main/guides/kafka.adoc:409
#, no-wrap
msgid "kafka-one-app-one-consumer.png"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:412
#, no-wrap
msgid "*Multiple consumer threads inside a consumer group*\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:416
msgid "For a given application instance, the number of consumers inside the consumer group can be configured using `mp.messaging.incoming.$channel.partitions` property.  The partitions of the subscribed topic will be divided among the consumer threads.  Note that if the `partitions` value exceed the number of partitions of the topic, some consumer threads won't be assigned any partitions."
msgstr ""

#. type: Target for macro image
#: upstream/_versions/main/guides/kafka.adoc:417
#, no-wrap
msgid "kafka-one-app-two-consumers.png"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:420
#, no-wrap
msgid "*Multiple consumer applications inside a consumer group*\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:423
msgid "Similar to the previous example, multiple instances of an application can subscribe to a single consumer group, configured via `mp.messaging.incoming.$channel.group.id` property, or left default to the application name.  This in turn will divide partitions of the topic among application instances."
msgstr ""

#. type: Target for macro image
#: upstream/_versions/main/guides/kafka.adoc:424
#, no-wrap
msgid "kafka-two-app-one-consumer-group.png"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:427
#, no-wrap
msgid "*Pub/Sub: Multiple consumer groups subscribed to a topic*\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:431
msgid "Lastly different applications can subscribe independently to same topics using different *consumer group ids*.  For example, messages published to a topic called _orders_ can be consumed independently on two consumer applications, one with `mp.messaging.incoming.orders.group.id=invoicing` and second with `mp.messaging.incoming.orders.group.id=shipping`.  Different consumer groups can thus scale independently according to the message consumption requirements."
msgstr ""

#. type: Target for macro image
#: upstream/_versions/main/guides/kafka.adoc:432
#, no-wrap
msgid "kafka-two-app-two-consumer-groups.png"
msgstr ""

#. type: Title ====
#: upstream/_versions/main/guides/kafka.adoc:434
#, fuzzy, no-wrap
#| msgid "*consumer-rebalance-listener.name*"
msgid "Consumer Rebalance Listener"
msgstr "*consumer-rebalance-listener.name*"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:441
msgid "Inside a consumer group, as new group members arrive and old members leave, the partitions are re-assigned so that each member receives a proportional share of the partitions.  This is known as rebalancing the group.  To handle offset commit and assigned partitions yourself, you can provide a consumer rebalance listener.  To achieve this, implement the `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` interface and expose it as a CDI bean with the `@Idenfier` qualifier.  A common use case is to store offset in a separate data store to implement exactly-once semantic, or starting the processing at a specific offset."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:445
msgid "The listener is invoked every time the consumer topic/partition assignment changes.  For example, when the application starts, it invokes the `partitionsAssigned` callback with the initial set of topics/partitions associated with the consumer.  If, later, this set changes, it calls the `partitionsRevoked` and `partitionsAssigned` callbacks again, so you can implement custom logic."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:448
msgid "Note that the rebalance listener methods are called from the Kafka polling thread and **will** block the caller thread until completion.  That’s because the rebalance protocol has synchronization barriers, and using asynchronous code in a rebalance listener may be executed after the synchronization barrier."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:450
msgid "When topics/partitions are assigned or revoked from a consumer, it pauses the message delivery and resumes once the rebalance completes."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:454
msgid "If the rebalance listener handles offset commit on behalf of the user (using the `NONE` commit strategy), the rebalance listener must commit the offset synchronously in the partitionsRevoked callback.  We also recommend applying the same logic when the application stops."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:456
#, fuzzy
#| msgid ""
#| "The name set in `javax.inject.Named` of a bean that implements `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener`. If set, this rebalance listener is applied to the consumer.\n"
#| "\n"
#| "Type: _string_"
msgid "Unlike the `ConsumerRebalanceListener` from Apache Kafka, the `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` methods pass the Kafka Consumer and the set of topics/partitions."
msgstr ""
"`io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` を実装するBeanの `javax.inject.Named` で設定された名前です。設定された場合、このリバランスリスナーはコンシューマーに適用されます。\n"
"\n"
"Type: _string_"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:460
msgid "In the following example we set-up a consumer that always starts on messages from at most 10 minutes ago (or offset 0).  First we need to provide a bean that implements `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` and is annotated with `io.smallrye.common.annotation.Identifier`.  We then must configure our inbound connector to use this bean."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:464
#: upstream/_versions/main/guides/kafka.adoc:514
#, no-wrap
msgid "package inbound;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:470
#, no-wrap
msgid ""
"import io.smallrye.common.annotation.Identifier;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener;\n"
"import org.apache.kafka.clients.consumer.Consumer;\n"
"import org.apache.kafka.clients.consumer.OffsetAndTimestamp;\n"
"import org.apache.kafka.clients.consumer.TopicPartition;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:476
#, fuzzy, no-wrap
#| msgid ""
#| "import javax.enterprise.context.ApplicationScoped;\n"
#| "import javax.transaction.Transactional;\n"
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import java.util.Collection;\n"
"import java.util.HashMap;\n"
"import java.util.Map;\n"
"import java.util.logging.Logger;\n"
msgstr ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.transaction.Transactional;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:480
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"@Identifier(\"rebalanced-example.rebalancer\")\n"
"public class KafkaRebalancedConsumerRebalanceListener implements KafkaConsumerRebalanceListener {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:482
#, no-wrap
msgid "    private static final Logger LOGGER = Logger.getLogger(KafkaRebalancedConsumerRebalanceListener.class.getName());\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:494
#, no-wrap
msgid ""
"    /**\n"
"     * When receiving a list of partitions, will search for the earliest offset within 10 minutes\n"
"     * and seek the consumer to it.\n"
"     *\n"
"     * @param consumer   underlying consumer\n"
"     * @param partitions set of assigned topic partitions\n"
"     */\n"
"    @Override\n"
"    public void onPartitionsAssigned(Consumer<?, ?> consumer, Collection<TopicPartition> partitions) {\n"
"        long now = System.currentTimeMillis();\n"
"        long shouldStartAt = now - 600_000L; //10 minute ago\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:507
#, no-wrap
msgid ""
"        Map<TopicPartition, Long> request = new HashMap<>();\n"
"        for (TopicPartition partition : partitions) {\n"
"            LOGGER.info(\"Assigned \" + partition);\n"
"            request.put(partition, shouldStartAt);\n"
"        }\n"
"        Map<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(request);\n"
"        for (Map.Entry<TopicPartition, OffsetAndTimestamp> position : offsets.entrySet()) {\n"
"            long target = position.getValue() == null ? 0L : position.getValue().offset();\n"
"            LOGGER.info(\"Seeking position \" + target + \" for \" + position.getKey());\n"
"            consumer.seek(position.getKey(), target);\n"
"        }\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:518
#, fuzzy, no-wrap
#| msgid ""
#| "import io.smallrye.reactive.messaging.annotations.Broadcast;\n"
#| "import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
#| "import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
msgid ""
"import io.smallrye.reactive.messaging.kafka.IncomingKafkaRecord;\n"
"import org.eclipse.microprofile.reactive.messaging.Acknowledgment;\n"
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
msgstr ""
"import io.smallrye.reactive.messaging.annotations.Broadcast;\n"
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:522
#, fuzzy, no-wrap
#| msgid ""
#| "import javax.enterprise.context.ApplicationScoped;\n"
#| "import javax.transaction.Transactional;\n"
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import java.util.concurrent.CompletableFuture;\n"
"import java.util.concurrent.CompletionStage;\n"
msgstr ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.transaction.Transactional;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:525
#, fuzzy, no-wrap
#| msgid ""
#| "@ApplicationScoped\n"
#| "public class PriceStorage {\n"
msgid ""
"@ApplicationScoped\n"
"public class KafkaRebalancedConsumer {\n"
msgstr ""
"@ApplicationScoped\n"
"public class PriceStorage {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:533
#, no-wrap
msgid ""
"    @Incoming(\"rebalanced-example\")\n"
"    @Acknowledgment(Acknowledgment.Strategy.NONE)\n"
"    public CompletionStage<Void> consume(IncomingKafkaRecord<Integer, String> message) {\n"
"        // We don't need to ACK messages because in this example,\n"
"        // we set offset during consumer rebalance\n"
"        return CompletableFuture.completedFuture(null);\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:539
msgid "To configure the inbound connector to use the provided listener, we either set the consumer rebalance listener’s identifier: `mp.messaging.incoming.rebalanced-example.consumer-rebalance-listener.name=rebalanced-example.rebalancer`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:541
msgid "Or have the listener’s name be the same as the group id:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:543
msgid "`mp.messaging.incoming.rebalanced-example.group.id=rebalanced-example.rebalancer`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:545
msgid "Setting the consumer rebalance listener’s name takes precedence over using the group id."
msgstr ""

#. type: Title ====
#: upstream/_versions/main/guides/kafka.adoc:546
#, no-wrap
msgid "Using unique consumer groups"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:549
msgid "If you want to process all the records from a topic (from its beginning), you need:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:551
#, fuzzy
#| msgid "*auto.offset.reset*"
msgid "to set `auto.offset.reset = earliest`"
msgstr "*auto.offset.reset*"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:552
msgid "assign your consumer to a consumer group not used by any other application."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:555
msgid "Quarkus generates a UUID that changes between two executions (including in dev mode).  So, you are sure no other consumer uses it, and you receive a new unique group id every time your application starts."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:557
msgid "You can use that generated UUID as the consumer group as follows:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:562
#, no-wrap
msgid ""
"mp.messaging.incoming.your-channel.auto.offset.reset=earliest\n"
"mp.messaging.incoming.your-channel.group.id=${quarkus.uuid}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:565
msgid "If the `group.id` attribute is not set, it defaults the `quarkus.application.name` configuration property."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:567
#, no-wrap
msgid "Sending messages to Kafka"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:570
msgid "Configuration for the Kafka connector outgoing channels is similar to that of incoming:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:576
#, no-wrap
msgid ""
"%prod.kafka.bootstrap.servers=kafka:9092 <1>\n"
"mp.messaging.outgoing.prices-out.connector=smallrye-kafka <2>\n"
"mp.messaging.outgoing.prices-out.topic=prices <3>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:581
msgid "Configure the broker location for the production profile. You can configure it globally or per channel using `mp.messaging.outgoing.$channel.bootstrap.servers` property.  In dev mode and when running tests, link:kafka-dev-services[Dev Services for Kafka] automatically starts a Kafka broker.  When not provided, this property defaults to `localhost:9092`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:582
msgid "Configure the connector to manage the `prices-out` channel."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:583
msgid "By default, the topic name is same as the channel name. You can configure the topic attribute to override it."
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:588
msgid "Inside application configuration, channel names are unique.  Therefore, if you'd like to configure an incoming and outgoing channel on the same topic, you will need to name channels differently (like in the examples of this guide, `mp.messaging.incoming.prices` and `mp.messaging.outgoing.prices-out`)."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:592
msgid "Then, your application can generate messages and publish them to the `prices-out` channel.  It can use `double` payloads as in the following snippet:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:597
#, no-wrap
msgid ""
"import io.smallrye.mutiny.Multi;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
msgstr ""
"import io.smallrye.mutiny.Multi;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:601
#, fuzzy, no-wrap
#| msgid ""
#| "import javax.enterprise.context.ApplicationScoped;\n"
#| "import javax.transaction.Transactional;\n"
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import java.time.Duration;\n"
"import java.util.Random;\n"
msgstr ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.transaction.Transactional;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:604
#, fuzzy, no-wrap
#| msgid ""
#| "@ApplicationScoped\n"
#| "public class PriceStorage {\n"
msgid ""
"@ApplicationScoped\n"
"public class KafkaPriceProducer {\n"
msgstr ""
"@ApplicationScoped\n"
"public class PriceStorage {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:606
#: upstream/_versions/main/guides/kafka.adoc:878
#, fuzzy, no-wrap
#| msgid "    private Random random = new Random();\n"
msgid "    private final Random random = new Random();\n"
msgstr "    private Random random = new Random();\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:614
#, fuzzy, no-wrap
#| msgid ""
#| "    @Outgoing(\"generated-price\")                        // <1>\n"
#| "    public Multi<Integer> generate() {                  // <2>\n"
#| "        return Multi.createFrom().ticks().every(Duration.ofSeconds(5))\n"
#| "                .onOverflow().drop()\n"
#| "                .map(tick -> random.nextInt(100));\n"
#| "    }\n"
msgid ""
"    @Outgoing(\"prices-out\")\n"
"    public Multi<Double> generate() {\n"
"        // Build an infinite stream of random prices\n"
"        // It emits a price every second\n"
"        return Multi.createFrom().ticks().every(Duration.ofSeconds(1))\n"
"            .map(x -> random.nextDouble());\n"
"    }\n"
msgstr ""
"    @Outgoing(\"generated-price\")                        // <1>\n"
"    public Multi<Integer> generate() {                  // <2>\n"
"        return Multi.createFrom().ticks().every(Duration.ofSeconds(5))\n"
"                .onOverflow().drop()\n"
"                .map(tick -> random.nextInt(100));\n"
"    }\n"

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:621
msgid "You should not call methods annotated with `@Incoming` and/or `@Outgoing` directly from your code. They are invoked by the framework. Having user code invoking them would not have the expected outcome."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:625
msgid "Note that the `generate` method returns a `Multi<Double>`, which implements the Reactive Streams `Publisher` interface.  This publisher will be used by the framework to generate messages and send them to the configured Kafka topic."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:627
msgid "Instead of returning a payload, you can return a `io.smallrye.reactive.messaging.kafka.Record` to send key/value pairs:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:635
#, fuzzy, no-wrap
#| msgid ""
#| "    @Outgoing(\"generated-price\")                        // <1>\n"
#| "    public Multi<Integer> generate() {                  // <2>\n"
#| "        return Multi.createFrom().ticks().every(Duration.ofSeconds(5))\n"
#| "                .onOverflow().drop()\n"
#| "                .map(tick -> random.nextInt(100));\n"
#| "    }\n"
msgid ""
"@Outgoing(\"out\")\n"
"public Multi<Record<String, Double>> generate() {\n"
"    return Multi.createFrom().ticks().every(Duration.ofSeconds(1))\n"
"        .map(x -> Record.of(\"my-key\", random.nextDouble()));\n"
"}\n"
msgstr ""
"    @Outgoing(\"generated-price\")                        // <1>\n"
"    public Multi<Integer> generate() {                  // <2>\n"
"        return Multi.createFrom().ticks().every(Duration.ofSeconds(5))\n"
"                .onOverflow().drop()\n"
"                .map(tick -> random.nextInt(100));\n"
"    }\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:638
msgid "Payload can be wrapped inside `org.eclipse.microprofile.reactive.messaging.Message` to have more control on the written records:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:651
#, no-wrap
msgid ""
"@Outgoing(\"generated-price\")\n"
"public Multi<Message<Double>> generate() {\n"
"    return Multi.createFrom().ticks().every(Duration.ofSeconds(1))\n"
"            .map(x -> Message.of(random.nextDouble())\n"
"                    .addMetadata(OutgoingKafkaRecordMetadata.<String>builder()\n"
"                            .withKey(\"my-key\")\n"
"                            .withTopic(\"my-key-prices\")\n"
"                            .withHeaders(new RecordHeaders().add(\"my-header\", \"value\".getBytes()))\n"
"                            .build()));\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:656
msgid "`OutgoingKafkaRecordMetadata` allows to set metadata attributes of the Kafka record, such as `key`, `topic`, `partition` or `timestamp`.  One use case is to dynamically select the destination topic of a message.  In this case, instead of configuring the topic inside your application configuration file, you need to use the outgoing metadata to set the name of the topic."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:659
msgid "Other than method signatures returning a Reactive Stream `Publisher` (`Multi` being an implementation of `Publisher`), outgoing method can also return single message.  In this case the producer will use this method as generator to create an infinite stream."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:663
#, no-wrap
msgid "@Outgoing(\"prices-out\") T generate(); // T excluding void\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:665
#, no-wrap
msgid "@Outgoing(\"prices-out\") Message<T> generate();\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:667
#, no-wrap
msgid "@Outgoing(\"prices-out\") Uni<T> generate();\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:669
#, no-wrap
msgid "@Outgoing(\"prices-out\") Uni<Message<T>> generate();\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:671
#, no-wrap
msgid "@Outgoing(\"prices-out\") CompletionStage<T> generate();\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:673
#, no-wrap
msgid "@Outgoing(\"prices-out\") CompletionStage<Message<T>> generate();\n"
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:675
#, no-wrap
msgid "Sending messages with @Emitter"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:678
msgid "Sometimes, you need to have an imperative way of sending messages."
msgstr "時には、命令的な方法でメッセージを送ることが必要になる場合もあります。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:681
#, fuzzy
#| msgid "For example, if you need to send a message to a stream, from inside a REST endpoint, when receiving a POST request.  In this case, you cannot use `@Output` because your method has parameters."
msgid "For example, if you need to send a message to a stream when receiving a POST request inside a REST endpoint.  In this case, you cannot use `@Outgoing` because your method has parameters."
msgstr "例えば、POST リクエストを受信したときに、REST エンドポイントの内部からストリームにメッセージを送信する必要があるとします。この場合、メソッドにはパラメーターがあるため、`@Output` を使用することはできません。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:683
msgid "For this, you can use an `Emitter`."
msgstr "この場合には `Emitter` が利用できます。"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:688
#: upstream/_versions/main/guides/kafka.adoc:1615
#: upstream/_versions/main/guides/kafka.adoc:1663
#: upstream/_versions/main/guides/kafka.adoc:1881
#, no-wrap
msgid ""
"import org.eclipse.microprofile.reactive.messaging.Channel;\n"
"import org.eclipse.microprofile.reactive.messaging.Emitter;\n"
msgstr ""
"import org.eclipse.microprofile.reactive.messaging.Channel;\n"
"import org.eclipse.microprofile.reactive.messaging.Emitter;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:694
#: upstream/_versions/main/guides/kafka.adoc:739
#: upstream/_versions/main/guides/kafka.adoc:773
#, no-wrap
msgid ""
"import javax.inject.Inject;\n"
"import javax.ws.rs.POST;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.Consumes;\n"
"import javax.ws.rs.core.MediaType;\n"
msgstr ""
"import javax.inject.Inject;\n"
"import javax.ws.rs.POST;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.Consumes;\n"
"import javax.ws.rs.core.MediaType;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:701
#, fuzzy, no-wrap
#| msgid "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"
msgid ""
"    @Inject\n"
"    @Channel(\"price-create\")\n"
"    Emitter<Double> priceEmitter;\n"
msgstr "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:708
#, fuzzy, no-wrap
#| msgid ""
#| "    @POST\n"
#| "    @Consumes(MediaType.TEXT_PLAIN)\n"
#| "    public void addPrice(Double price) {\n"
#| "        priceEmitter.send(price);\n"
#| "    }\n"
#| "}\n"
msgid ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public void addPrice(Double price) {\n"
"        CompletionStage<Void> ack = priceEmitter.send(price);\n"
"    }\n"
"}\n"
msgstr ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public void addPrice(Double price) {\n"
"        priceEmitter.send(price);\n"
"    }\n"
"}\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:711
msgid "Sending a payload returns a `CompletionStage`, completed when the message is acked. If the message transmission fails, the `CompletionStage` is completed exceptionally with the reason of the nack."
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:715
#, fuzzy
#| msgid "The `Emitter` configuration is done the same way as the other stream configuration used by `@Incoming` and `@Outgoing`.  In addition, you can use `@OnOverflow` to configure back-pressure strategy."
msgid "The `Emitter` configuration is done the same way as the other stream configuration used by `@Incoming` and `@Outgoing`."
msgstr "`Emitter` の設定は、`@Incoming` と `@Outgoing` が使用する他のストリームの設定と同じ方法で行います。さらに、`@OnOverflow` を使用して、バックプレッシャー戦略を設定することができます。"

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:724
msgid "Using the `Emitter` you are sending messages from your imperative code to reactive messaging.  These messages are stored in a queue until they are sent.  If the Kafka producer client can't keep up with messages trying to be sent over to Kafka, this queue can become a memory hog and you may even run out of memory.  You can use `@OnOverflow` to configure back-pressure strategy.  It lets you configure the size of the queue (default is 256) and the strategy to apply when the buffer size is reached. Available strategies are `DROP`, `LATEST`, `FAIL`, `BUFFER`, `UNBOUNDED_BUFFER` and `NONE`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:727
msgid "With the `Emitter` API, you can also encapsulate the outgoing payload inside `Message<T>`. As with the previous examples, `Message` lets you handle the ack/nack cases differently."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:733
#, fuzzy, no-wrap
#| msgid ""
#| "import org.eclipse.microprofile.reactive.messaging.Channel;\n"
#| "import org.eclipse.microprofile.reactive.messaging.Emitter;\n"
msgid ""
"import java.util.concurrent.CompletableFuture;\n"
"import org.eclipse.microprofile.reactive.messaging.Channel;\n"
"import org.eclipse.microprofile.reactive.messaging.Emitter;\n"
msgstr ""
"import org.eclipse.microprofile.reactive.messaging.Channel;\n"
"import org.eclipse.microprofile.reactive.messaging.Emitter;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:744
#, no-wrap
msgid "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"
msgstr "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:759
#, no-wrap
msgid ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public void addPrice(Double price) {\n"
"        priceEmitter.send(Message.of(price)\n"
"            .withAck(() -> {\n"
"                // Called when the message is acked\n"
"                return CompletableFuture.completedFuture(null);\n"
"            })\n"
"            .withNack(throwable -> {\n"
"                // Called when the message is nacked\n"
"                return CompletableFuture.completedFuture(null);\n"
"            }));\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:763
msgid "If you prefer using Reactive Stream APIs, you can use `MutinyEmitter` that will return `Uni<Void>` from the `send` method.  You can therefore use Mutiny APIs for handling downstream messages and errors."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:767
#: upstream/_versions/main/guides/kafka.adoc:1918
#, fuzzy, no-wrap
#| msgid "`org.eclipse.microprofile.reactive.messaging.Channel`"
msgid "import org.eclipse.microprofile.reactive.messaging.Channel;\n"
msgstr "`org.eclipse.microprofile.reactive.messaging.Channel`"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:775
#, fuzzy, no-wrap
#| msgid "`io.smallrye.reactive.messaging.annotations.Blocking`"
msgid "import io.smallrye.reactive.messaging.MutinyEmitter;\n"
msgstr "`io.smallrye.reactive.messaging.annotations.Blocking`"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:782
#, fuzzy, no-wrap
#| msgid "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"
msgid ""
"    @Inject\n"
"    @Channel(\"price-create\")\n"
"    MutinyEmitter<Double> priceEmitter;\n"
msgstr "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:791
#, fuzzy, no-wrap
#| msgid ""
#| "    @POST\n"
#| "    @Consumes(MediaType.TEXT_PLAIN)\n"
#| "    public void addPrice(Double price) {\n"
#| "        priceEmitter.send(price);\n"
#| "    }\n"
#| "}\n"
msgid ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public Uni<String> addPrice(Double price) {\n"
"        return quoteRequestEmitter.send(price)\n"
"                .map(x -> \"ok\")\n"
"                .onFailure().recoverWithItem(\"ko\");\n"
"    }\n"
"}\n"
msgstr ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public void addPrice(Double price) {\n"
"        priceEmitter.send(price);\n"
"    }\n"
"}\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:795
msgid "It is also possible to block on sending the event to the emitter with the `sendAndAwait` method.  It will only return from the method when the event is acked or nacked by the receiver."
msgstr ""

#. type: Block title
#: upstream/_versions/main/guides/kafka.adoc:797
#, no-wrap
msgid "Deprecation"
msgstr "非推奨"

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:800
msgid "The `io.smallrye.reactive.messaging.annotations.Emitter`, `io.smallrye.reactive.messaging.annotations.Channel` and `io.smallrye.reactive.messaging.annotations.OnOverflow` classes are now deprecated and replaced by:"
msgstr "`io.smallrye.reactive.messaging.annotations.Emitter`、`io.smallrye.reactive.messaging.annotations.Channel`、`io.smallrye.reactive.messaging.annotations.OnOverflow` クラスは現在非推奨となっており、以下のように置き換えられています。"

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:802
msgid "`org.eclipse.microprofile.reactive.messaging.Emitter`"
msgstr "`org.eclipse.microprofile.reactive.messaging.Emitter`"

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:803
msgid "`org.eclipse.microprofile.reactive.messaging.Channel`"
msgstr "`org.eclipse.microprofile.reactive.messaging.Channel`"

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:804
msgid "`org.eclipse.microprofile.reactive.messaging.OnOverflow`"
msgstr "`org.eclipse.microprofile.reactive.messaging.OnOverflow`"

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:806
msgid "The new `Emitter.send` method returns a `CompletionStage` completed when the produced message is acknowledged."
msgstr "新しい `Emitter.send` メソッドは、生成されたメッセージが確認されると、`CompletionStage` の完了を返します。"

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:808
#, no-wrap
msgid "Write Acknowledgement"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:812
msgid "When Kafka broker receives a record, its acknowledgement can take time depending on the configuration.  Also, it stores in-memory the records that cannot be written."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:815
msgid "By default, the connector does wait for Kafka to acknowledge the record to continue the processing (acknowledging the received Message).  You can disable this by setting the `waitForWriteCompletion` attribute to `false`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:817
msgid "Note that the `acks` attribute has a huge impact on the record acknowledgement."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:819
msgid "If a record cannot be written, the message is nacked."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:820
#, no-wrap
msgid "Backpressure"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:824
msgid "The Kafka outbound connector handles back-pressure, monitoring the number of in-flight messages waiting to be written to the Kafka broker.  The number of in-flight messages is configured using the `max-inflight-messages` attribute and defaults to 1024."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:829
msgid "The connector only sends that amount of messages concurrently.  No other messages will be sent until at least one in-flight message gets acknowledged by the broker.  Then, the connector writes a new message to Kafka when one of the broker’s in-flight messages get acknowledged.  Be sure to configure Kafka’s `batch.size` and `linger.ms` accordingly."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:832
msgid "You can also remove the limit of in-flight messages by setting `max-inflight-messages` to `0`.  However, note that the Kafka producer may block if the number of requests reaches `max.in.flight.requests.per.connection`."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:833
#, no-wrap
msgid "Retrying message dispatch"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:838
msgid "When the Kafka producer receives an error from the server, if it is a transient, recoverable error, the client will retry sending the batch of messages.  This behavior is controlled by `retries` and `retry.backoff.ms` parameters.  In addition to this, SmallRye Reactive Messaging will retry individual messages on recoverable errors, depending on the `retries` and `delivery.timeout.ms` parameters."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:841
msgid "Note that while having retries in a reliable system is a best practice, the `max.in.flight.requests.per.connection` parameter defaults to `5`, meaning that the order of the messages is not guaranteed.  If the message order is a must for your use case, setting `max.in.flight.requests.per.connection` to `1` will make sure a single batch of messages is sent at a time, in the expense of limiting the throughput of the producer."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:843
msgid "For applying retry mechanism on processing errors, see the section on <<retrying-processing>>."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:844
#, no-wrap
msgid "In-memory channels"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:849
msgid "In some use cases, it is convenient to use the messaging patterns to transfer messages inside the same application.  When you don't connect a channel to a messaging backend like Kafka, everything happens in-memory, and the streams are created by chaining methods together.  Each chain is still a reactive stream and enforces the back-pressure protocol."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:853
msgid "The framework verifies that the producer/consumer chain is complete, meaning that if the application writes messages into an in-memory channel (using a method with only `@Outgoing`, or an `Emitter`), it must also consume the messages from within the application (using a method with only `@Incoming` or using an unmanaged stream)."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:855
#, no-wrap
msgid "Broadcasting messages on multiple consumers"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:860
msgid "By default, a channel can be linked to a single consumer, using `@Incoming` method or `@Channel` reactive stream.  At application startup, channels are verified to form a chain of consumers and producers with single consumer and producer.  You can override this behavior by setting `mp.messaging.$channel.broadcast=true` on a channel."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:862
msgid "In case of in-memory channels, `@Broadcast` annotation can be used on the `@Outgoing` method. For example,"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:866
#, fuzzy, no-wrap
#| msgid ""
#| "import java.time.Duration;\n"
#| "import java.util.Random;\n"
msgid "import java.util.Random;\n"
msgstr ""
"import java.time.Duration;\n"
"import java.util.Random;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:871
#: upstream/_versions/main/guides/kafka.adoc:913
#: upstream/_versions/main/guides/kafka.adoc:941
#, fuzzy, no-wrap
#| msgid ""
#| "import org.eclipse.microprofile.reactive.messaging.Channel;\n"
#| "import org.eclipse.microprofile.reactive.messaging.Emitter;\n"
msgid ""
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
msgstr ""
"import org.eclipse.microprofile.reactive.messaging.Channel;\n"
"import org.eclipse.microprofile.reactive.messaging.Emitter;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:873
#, fuzzy, no-wrap
#| msgid "`io.smallrye.reactive.messaging.annotations.Blocking`"
msgid "import io.smallrye.reactive.messaging.annotations.Broadcast;\n"
msgstr "`io.smallrye.reactive.messaging.annotations.Blocking`"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:876
#, fuzzy, no-wrap
#| msgid ""
#| "@ApplicationScoped\n"
#| "public class PriceStorage {\n"
msgid ""
"@ApplicationScoped\n"
"public class MultipleConsumer {\n"
msgstr ""
"@ApplicationScoped\n"
"public class PriceStorage {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:884
#, no-wrap
msgid ""
"    @Outgoing(\"in-memory-channel\")\n"
"    @Broadcast\n"
"    double generate() {\n"
"        return random.nextDouble();\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:889
#, no-wrap
msgid ""
"    @Incoming(\"in-memory-channel\")\n"
"    void consumeAndLog(double price) {\n"
"        System.out.println(price);\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:896
#, no-wrap
msgid ""
"    @Incoming(\"in-memory-channel\")\n"
"    @Outgoing(\"prices2\")\n"
"    double consumeAndSend(double price) {\n"
"        return price;\n"
"    }\n"
"}\n"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:902
msgid "Reciprocally, multiple producers on the same channel can be merged by setting `mp.messaging.incoming.$channel.merge=true`.  On the `@Incoming` methods, you can control how multiple channels are merged using the `@Merge` annotation."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:904
#, no-wrap
msgid "Processing Messages"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:908
msgid "Applications streaming data often need to consume some events from a topic, process them and publish the result to a different topic.  A processor method can be simply implemented using both the `@Incoming` and `@Outgoing` annotations:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:918
#: upstream/_versions/main/guides/kafka.adoc:946
#, fuzzy, no-wrap
#| msgid ""
#| "@ApplicationScoped\n"
#| "public class PriceStorage {\n"
msgid ""
"@ApplicationScoped\n"
"public class PriceProcessor {\n"
msgstr ""
"@ApplicationScoped\n"
"public class PriceStorage {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:920
#: upstream/_versions/main/guides/kafka.adoc:948
#: upstream/_versions/main/guides/kafka.adoc:1087
#, no-wrap
msgid "    private static final double CONVERSION_RATE = 0.88;\n"
msgstr "    private static final double CONVERSION_RATE = 0.88;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:926
#, fuzzy, no-wrap
#| msgid ""
#| "    @Incoming(\"fruit-in\")\n"
#| "    @Outgoing(\"fruit-out\")\n"
#| "    @Broadcast\n"
#| "    public Fruit process(Fruit fruit) {\n"
#| "        fruit.price = fruit.price * CONVERSION_RATE;\n"
#| "        return fruit;\n"
#| "    }\n"
msgid ""
"    @Incoming(\"price-in\")\n"
"    @Outgoing(\"price-out\")\n"
"    public double process(double price) {\n"
"        return price * CONVERSION_RATE;\n"
"    }\n"
msgstr ""
"    @Incoming(\"fruit-in\")\n"
"    @Outgoing(\"fruit-out\")\n"
"    @Broadcast\n"
"    public Fruit process(Fruit fruit) {\n"
"        fruit.price = fruit.price * CONVERSION_RATE;\n"
"        return fruit;\n"
"    }\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:932
msgid "The parameter of the `process` method is the incoming message payload, whereas the return value will be used as the outgoing message payload.  Previously mentioned signatures for parameter and return types are also supported, such as `Message<T>`, `Record<K, V>`, etc."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:934
msgid "You can apply asynchronous stream processing by consuming and returning reactive stream `Multi<T>` type:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:943
#, no-wrap
msgid "import io.smallrye.mutiny.Multi;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:954
#, fuzzy, no-wrap
#| msgid ""
#| "    @Incoming(\"fruit-in\")\n"
#| "    @Outgoing(\"fruit-out\")\n"
#| "    @Broadcast\n"
#| "    public Fruit process(Fruit fruit) {\n"
#| "        fruit.price = fruit.price * CONVERSION_RATE;\n"
#| "        return fruit;\n"
#| "    }\n"
msgid ""
"    @Incoming(\"price-in\")\n"
"    @Outgoing(\"price-out\")\n"
"    public Multi<Double> process(Multi<Integer> prices) {\n"
"        return prices.filter(p -> p > 100).map(p -> p * CONVERSION_RATE);\n"
"    }\n"
msgstr ""
"    @Incoming(\"fruit-in\")\n"
"    @Outgoing(\"fruit-out\")\n"
"    @Broadcast\n"
"    public Fruit process(Fruit fruit) {\n"
"        fruit.price = fruit.price * CONVERSION_RATE;\n"
"        return fruit;\n"
"    }\n"

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:958
#, no-wrap
msgid "Propagating Record Key"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:961
msgid "When processing messages, you can propagate incoming record key to the outgoing record."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:964
msgid "Enabled with `mp.messaging.outgoing.$channel.propagate-record-key=true` configuration, record key propagation produces the outgoing record with the same _key_ as the incoming record."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:967
msgid "If the outgoing record already contains a _key_, it *won't be overridden* by the incoming record key.  If the incoming record does have a _null_ key, the `mp.messaging.outgoing.$channel.key` property is used."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:969
#, no-wrap
msgid "Accessing Kafka clients directly"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:973
msgid "In rare cases, you may need to access the underlying Kafka clients.  `KafkaClientService` provides thread-safe access to `Producer` and `Consumer`."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:979
#, fuzzy, no-wrap
#| msgid ""
#| "import javax.enterprise.context.ApplicationScoped;\n"
#| "import javax.transaction.Transactional;\n"
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.enterprise.event.Observes;\n"
"import javax.inject.Inject;\n"
msgstr ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.transaction.Transactional;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:981
#, no-wrap
msgid "import org.apache.kafka.clients.producer.ProducerRecord;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:986
#, no-wrap
msgid ""
"import io.quarkus.runtime.StartupEvent;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaClientService;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaConsumer;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaProducer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:989
#, fuzzy, no-wrap
#| msgid ""
#| "@ApplicationScoped\n"
#| "public class PriceStorage {\n"
msgid ""
"@ApplicationScoped\n"
"public class PriceSender {\n"
msgstr ""
"@ApplicationScoped\n"
"public class PriceStorage {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:992
#, no-wrap
msgid ""
"    @Inject\n"
"    KafkaClientService clientService;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:999
#, no-wrap
msgid ""
"    void onStartup(@Observes StartupEvent startupEvent) {\n"
"        KafkaProducer<String, Double> producer = clientService.getProducer(\"generated-price\");\n"
"        producer.runOnSendingThread(client -> client.send(new ProducerRecord<>(\"prices\", 2.4)))\n"
"            .await().indefinitely();\n"
"    }\n"
"}\n"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:1004
msgid "The `KafkaClientService` is an experimental API and can change in the future."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1007
msgid "You can also get the Kafka configuration injected to your application and create Kafka producer, consumer and admin clients directly:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1014
#, no-wrap
msgid ""
"import io.smallrye.common.annotation.Identifier;\n"
"import org.apache.kafka.clients.admin.AdminClient;\n"
"import org.apache.kafka.clients.admin.AdminClientConfig;\n"
"import org.apache.kafka.clients.admin.KafkaAdminClient;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1020
#, fuzzy, no-wrap
#| msgid ""
#| "import javax.enterprise.context.ApplicationScoped;\n"
#| "import javax.transaction.Transactional;\n"
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.enterprise.inject.Produces;\n"
"import javax.inject.Inject;\n"
"import java.util.HashMap;\n"
"import java.util.Map;\n"
msgstr ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.transaction.Transactional;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1023
#, fuzzy, no-wrap
#| msgid ""
#| "@ApplicationScoped\n"
#| "public class PriceStorage {\n"
msgid ""
"@ApplicationScoped\n"
"public class KafkaClients {\n"
msgstr ""
"@ApplicationScoped\n"
"public class PriceStorage {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1027
#, no-wrap
msgid ""
"    @Inject\n"
"    @Identifier(\"default-kafka-broker\")\n"
"    Map<String, Object> config;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1038
#, no-wrap
msgid ""
"    @Produces\n"
"    AdminClient getAdmin() {\n"
"        Map<String, Object> copy = new HashMap<>();\n"
"        for (Map.Entry<String, Object> entry : config.entrySet()) {\n"
"            if (AdminClientConfig.configNames().contains(entry.getKey())) {\n"
"                copy.put(entry.getKey(), entry.getValue());\n"
"            }\n"
"        }\n"
"        return KafkaAdminClient.create(copy);\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1044
msgid "This configuration map will contain all Kafka related properties configured inside `application.properties` file."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1046
#, no-wrap
msgid "JSON serialization"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1049
msgid "Quarkus has built-in capabilities to deal with JSON Kafka messages."
msgstr "Quarkus には、JSON Kafka メッセージを扱う機能が組み込まれています。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1051
#, fuzzy
#| msgid "Imagine we have a `Fruit` pojo as follows:"
msgid "Imagine we have a `Fruit` data class as follows:"
msgstr "以下のように `Fruit` の pojo があると想像してみてください。"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1055
#, no-wrap
msgid "public class Fruit {\n"
msgstr "public class Fruit {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1058
#, no-wrap
msgid ""
"    public String name;\n"
"    public int price;\n"
msgstr ""
"    public String name;\n"
"    public int price;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1061
#, no-wrap
msgid ""
"    public Fruit() {\n"
"    }\n"
msgstr ""
"    public Fruit() {\n"
"    }\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1067
#, no-wrap
msgid ""
"    public Fruit(String name, int price) {\n"
"        this.name = name;\n"
"        this.price = price;\n"
"    }\n"
"}\n"
msgstr ""
"    public Fruit(String name, int price) {\n"
"        this.name = name;\n"
"        this.price = price;\n"
"    }\n"
"}\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1070
msgid "And we want to use it to receive messages from Kafka, make some price transformation, and send messages back to Kafka."
msgstr "そして、Kafka からメッセージを受信して、何らかの価格変換を行い、Kafka にメッセージを送り返すために使いたいと考えています。"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1076
#, no-wrap
msgid ""
"import io.smallrye.reactive.messaging.annotations.Broadcast;\n"
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
msgstr ""
"import io.smallrye.reactive.messaging.annotations.Broadcast;\n"
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1085
#, fuzzy, no-wrap
#| msgid ""
#| "/**\n"
#| "* A bean consuming data from the \"fruit-in\" Kafka topic and applying some price conversion.\n"
#| "* The result is pushed to the \"fruit-out\" stream.\n"
#| "*/\n"
#| "@ApplicationScoped\n"
#| "public class FruitProcessor {\n"
msgid ""
"/**\n"
"* A bean consuming data from the \"fruit-in\" channel and applying some price conversion.\n"
"* The result is pushed to the \"fruit-out\" channel.\n"
"*/\n"
"@ApplicationScoped\n"
"public class FruitProcessor {\n"
msgstr ""
"/**\n"
"* A bean consuming data from the \"fruit-in\" Kafka topic and applying some price conversion.\n"
"* The result is pushed to the \"fruit-out\" stream.\n"
"*/\n"
"@ApplicationScoped\n"
"public class FruitProcessor {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1095
#, no-wrap
msgid ""
"    @Incoming(\"fruit-in\")\n"
"    @Outgoing(\"fruit-out\")\n"
"    @Broadcast\n"
"    public Fruit process(Fruit fruit) {\n"
"        fruit.price = fruit.price * CONVERSION_RATE;\n"
"        return fruit;\n"
"    }\n"
msgstr ""
"    @Incoming(\"fruit-in\")\n"
"    @Outgoing(\"fruit-out\")\n"
"    @Broadcast\n"
"    public Fruit process(Fruit fruit) {\n"
"        fruit.price = fruit.price * CONVERSION_RATE;\n"
"        return fruit;\n"
"    }\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1100
msgid "To do this, we will need to setup JSON serialization with Jackson or JSON-B."
msgstr "そのためには、Jackson や JSON-B で JSON シリアライゼーションを設定する必要があります。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1102
msgid "With JSON serialization correctly configured, you can also use `Publisher<Fruit>` and `Emitter<Fruit>`."
msgstr "JSON シリアライゼーションが正しく設定されていれば、 `Publisher<Fruit>` や `Emitter<Fruit>` も利用できます。"

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1104
#, no-wrap
msgid "Serializing via Jackson"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1107
msgid "First, you need to include the `quarkus-jackson` extension."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1114
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-jackson</artifactId>\n"
"</dependency>\n"
msgstr ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-jackson</artifactId>\n"
"</dependency>\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1118
msgid "There is an existing `ObjectMapperSerializer` that can be used to serialize all data objects via Jackson.  You may create an empty subclass if you want to use <<serialization-autodetection>>."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1122
msgid "By default, the `ObjectMapperSerializer` serializes null as the `\"null\"` String, this can be customized by setting the Kafka configuration property `json.serialize.null-as-null=true` which will serialize null as `null`.  This is handy when using a compacted topic, as `null` is used as a tombstone to know which messages delete during compaction phase."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1125
msgid "The corresponding deserializer class needs to be subclassed.  So, let's create a `FruitDeserializer` that extends the `ObjectMapperDeserializer`."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1129
#: upstream/_versions/main/guides/kafka.adoc:1162
#, no-wrap
msgid "package com.acme.fruit.jackson;\n"
msgstr "package com.acme.fruit.jackson;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1131
#: upstream/_versions/main/guides/kafka.adoc:1745
#: upstream/_versions/main/guides/kafka.adoc:1831
#, no-wrap
msgid "import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;\n"
msgstr "import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1137
#: upstream/_versions/main/guides/kafka.adoc:1751
#: upstream/_versions/main/guides/kafka.adoc:1837
#, fuzzy, no-wrap
msgid ""
"public class FruitDeserializer extends ObjectMapperDeserializer<Fruit> {\n"
"    public FruitDeserializer() {\n"
"        super(Fruit.class);\n"
"    }\n"
"}\n"
msgstr ""
"public class FruitDeserializer extends ObjectMapperDeserializer<Fruit> {\n"
"    public FruitDeserializer(){\n"
"        // pass the class to the parent.\n"
"        super(Fruit.class);\n"
"    }\n"
"}\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1140
#, fuzzy
#| msgid "Finally, configure your streams to use the Jackson serializer and deserializer."
msgid "Finally, configure your channels to use the Jackson serializer and deserializer."
msgstr "最後に、Jackson シリアライザーとデシリアライザーを使用するようにストリームを設定します。"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1147
#, no-wrap
msgid ""
"# Configure the Kafka source (we read from it)\n"
"mp.messaging.incoming.fruit-in.connector=smallrye-kafka\n"
"mp.messaging.incoming.fruit-in.topic=fruit-in\n"
"mp.messaging.incoming.fruit-in.value.deserializer=com.acme.fruit.jackson.FruitDeserializer\n"
msgstr ""
"# Configure the Kafka source (we read from it)\n"
"mp.messaging.incoming.fruit-in.connector=smallrye-kafka\n"
"mp.messaging.incoming.fruit-in.topic=fruit-in\n"
"mp.messaging.incoming.fruit-in.value.deserializer=com.acme.fruit.jackson.FruitDeserializer\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1152
#, no-wrap
msgid ""
"# Configure the Kafka sink (we write to it)\n"
"mp.messaging.outgoing.fruit-out.connector=smallrye-kafka\n"
"mp.messaging.outgoing.fruit-out.topic=fruit-out\n"
"mp.messaging.outgoing.fruit-out.value.serializer=io.quarkus.kafka.client.serialization.ObjectMapperSerializer\n"
msgstr ""
"# Configure the Kafka sink (we write to it)\n"
"mp.messaging.outgoing.fruit-out.connector=smallrye-kafka\n"
"mp.messaging.outgoing.fruit-out.topic=fruit-out\n"
"mp.messaging.outgoing.fruit-out.value.serializer=io.quarkus.kafka.client.serialization.ObjectMapperSerializer\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1156
msgid "Now, your Kafka messages will contain a Jackson serialized representation of your `Fruit` data object.  In this case, the `deserializer` configuration is not necessary as the <<serialization-autodetection>> is enabled by default."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1158
msgid "If you want to deserialize a list of fruits, you need to create a deserializer with a Jackson `TypeReference` denoted the generic collection used."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1166
#, fuzzy, no-wrap
#| msgid "import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;\n"
msgid ""
"import java.util.List;\n"
"import com.fasterxml.jackson.core.type.TypeReference;\n"
"import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;\n"
msgstr "import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1174
#, fuzzy, no-wrap
msgid ""
"public class ListOfFruitDeserializer extends ObjectMapperDeserializer<List<Fruit>> {\n"
"    public ListOfFruitDeserializer() {\n"
"        TypeReference<List<Fruit>> listType = new TypeReference<>() {\n"
"        };\n"
"        super(listType);\n"
"    }\n"
"}\n"
msgstr ""
"public class FruitDeserializer extends ObjectMapperDeserializer<Fruit> {\n"
"    public FruitDeserializer(){\n"
"        // pass the class to the parent.\n"
"        super(Fruit.class);\n"
"    }\n"
"}\n"

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1177
#, no-wrap
msgid "Serializing via JSON-B"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1180
msgid "First, you need to include the `quarkus-jsonb` extension."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1187
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-jsonb</artifactId>\n"
"</dependency>\n"
msgstr ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-jsonb</artifactId>\n"
"</dependency>\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1191
msgid "There is an existing `JsonbSerializer` that can be used to serialize all data objects via JSON-B.  You may create an empty subclass if you want to use <<serialization-autodetection>>."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1195
msgid "By default, the `JsonbSerializer` serializes null as the `\"null\"` String, this can be customized by setting the Kafka configuration property `json.serialize.null-as-null=true` which will serialize null as `null`.  This is handy when using a compacted topic, as `null` is used as a tombstone to know which messages delete during compaction phase."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1198
msgid "The corresponding deserializer class needs to be subclassed.  So, let's create a `FruitDeserializer` that extends the generic `JsonbDeserializer`."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1202
#, no-wrap
msgid "package com.acme.fruit.jsonb;\n"
msgstr "package com.acme.fruit.jsonb;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1204
#, no-wrap
msgid "import io.quarkus.kafka.client.serialization.JsonbDeserializer;\n"
msgstr "import io.quarkus.kafka.client.serialization.JsonbDeserializer;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1210
#, fuzzy, no-wrap
msgid ""
"public class FruitDeserializer extends JsonbDeserializer<Fruit> {\n"
"    public FruitDeserializer() {\n"
"        super(Fruit.class);\n"
"    }\n"
"}\n"
msgstr ""
"public class FruitDeserializer extends JsonbDeserializer<Fruit> {\n"
"    public FruitDeserializer(){\n"
"        // pass the class to the parent.\n"
"        super(Fruit.class);\n"
"    }\n"
"}\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1213
#, fuzzy
#| msgid "Finally, configure your streams to use the JSON-B serializer and deserializer."
msgid "Finally, configure your channels to use the JSON-B serializer and deserializer."
msgstr "最後に、JSON-B シリアライザーとデシリアライザーを使用するようにストリームを設定します。"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1220
#, no-wrap
msgid ""
"# Configure the Kafka source (we read from it)\n"
"mp.messaging.incoming.fruit-in.connector=smallrye-kafka\n"
"mp.messaging.incoming.fruit-in.topic=fruit-in\n"
"mp.messaging.incoming.fruit-in.value.deserializer=com.acme.fruit.jsonb.FruitDeserializer\n"
msgstr ""
"# Configure the Kafka source (we read from it)\n"
"mp.messaging.incoming.fruit-in.connector=smallrye-kafka\n"
"mp.messaging.incoming.fruit-in.topic=fruit-in\n"
"mp.messaging.incoming.fruit-in.value.deserializer=com.acme.fruit.jsonb.FruitDeserializer\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1225
#, no-wrap
msgid ""
"# Configure the Kafka sink (we write to it)\n"
"mp.messaging.outgoing.fruit-out.connector=smallrye-kafka\n"
"mp.messaging.outgoing.fruit-out.topic=fruit-out\n"
"mp.messaging.outgoing.fruit-out.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer\n"
msgstr ""
"# Configure the Kafka sink (we write to it)\n"
"mp.messaging.outgoing.fruit-out.connector=smallrye-kafka\n"
"mp.messaging.outgoing.fruit-out.topic=fruit-out\n"
"mp.messaging.outgoing.fruit-out.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1228
#, fuzzy
#| msgid "Now, your Kafka messages will contain a JSON-B serialized representation of your Fruit pojo."
msgid "Now, your Kafka messages will contain a JSON-B serialized representation of your `Fruit` data object."
msgstr "これで、Kafka のメッセージには、JSON-B でシリアライズされた Fruit pojo の表現が含まれます。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1230
msgid "If you want to deserialize a list of fruits, you need to create a deserializer with a `Type` denoted the generic collection used."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1238
#, no-wrap
msgid ""
"package com.acme.fruit.jsonb;\n"
"import java.lang.reflect.Type;\n"
"import java.util.ArrayList;\n"
"import java.util.List;\n"
"import io.quarkus.kafka.client.serialization.JsonbDeserializer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1245
#, fuzzy, no-wrap
msgid ""
"public class ListOfFruitDeserializer extends JsonbDeserializer<List<Fruit>> {\n"
"    public ListOfFruitDeserializer() {\n"
"        Type listType = new ArrayList<MyEntity>() {}.getClass().getGenericSuperclass();\n"
"        super(listType);\n"
"    }\n"
"}\n"
msgstr ""
"public class FruitDeserializer extends JsonbDeserializer<Fruit> {\n"
"    public FruitDeserializer(){\n"
"        // pass the class to the parent.\n"
"        super(Fruit.class);\n"
"    }\n"
"}\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1249
msgid "If you don't want to create a deserializer for each data object, you can use the generic `io.vertx.kafka.client.serialization.JsonObjectDeserializer` that will deserialize to a `io.vertx.core.json.JsonObject`. The corresponding serializer can also be used: `io.vertx.kafka.client.serialization.JsonObjectSerializer`."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1250
#, no-wrap
msgid "Avro Serialization"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1253
#: upstream/_versions/main/guides/kafka.adoc:1325
msgid "This is described in a dedicated guide: link:kafka-schema-registry-avro[Using Apache Kafka with Schema Registry and Avro]."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1255
#, no-wrap
msgid "Serializer/deserializer autodetection"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1259
msgid "When using SmallRye Reactive Messaging with Kafka, Quarkus can often automatically detect the correct serializer and deserializer class.  This autodetection is based on declarations of `@Incoming` and `@Outgoing` methods, as well as injected ``@Channel``s."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1261
msgid "For example, if you declare"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1268
#, no-wrap
msgid ""
"@Outgoing(\"generated-price\")\n"
"public Multi<Integer> generate() {\n"
"    ...\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1271
msgid "and your configuration indicates that the `generated-price` channel uses the `smallrye-kafka` connector, then Quarkus will automatically set the `value.serializer` to Kafka's built-in `IntegerSerializer`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1273
msgid "Similarly, if you declare"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1280
#, no-wrap
msgid ""
"@Incoming(\"my-kafka-records\")\n"
"public void consume(KafkaRecord<Long, byte[]> record) {\n"
"    ...\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1283
msgid "and your configuration indicates that the `my-kafka-records` channel uses the `smallrye-kafka` connector, then Quarkus will automatically set the `key.deserializer` to Kafka's built-in `LongDeserializer`, as well as the `value.deserializer` to `ByteArrayDeserializer`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1285
msgid "Finally, if you declare"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1291
#, no-wrap
msgid ""
"@Inject\n"
"@Channel(\"price-create\")\n"
"Emitter<Double> priceEmitter;\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1294
msgid "and your configuration indicates that the `price-create` channel uses the `smallrye-kafka` connector, then Quarkus will automatically set the `value.serializer` to Kafka's built-in `DoubleSerializer`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1296
msgid "The full set of types supported by the serializer/deserializer autodetection is:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1298
msgid "`short` and `java.lang.Short`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1299
msgid "`int` and `java.lang.Integer`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1300
msgid "`long` and `java.lang.Long`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1301
msgid "`float` and `java.lang.Float`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1302
msgid "`double` and `java.lang.Double`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1303
msgid "`byte[]`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1304
msgid "`java.lang.String`"
msgstr "`java.lang.String`"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1305
msgid "`java.util.UUID`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1306
msgid "`java.nio.ByteBuffer`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1307
msgid "`org.apache.kafka.common.utils.Bytes`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1308
msgid "`io.vertx.core.buffer.Buffer`"
msgstr "`io.vertx.core.buffer.Buffer`"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1309
msgid "`io.vertx.core.json.JsonObject`"
msgstr "`io.vertx.core.json.JsonObject`"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1310
msgid "`io.vertx.core.json.JsonArray`"
msgstr "`io.vertx.core.json.JsonArray`"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1311
msgid "classes generated from Avro schemas, as well as Avro `GenericRecord`, if Confluent or Apicurio Registry _serde_ is present"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1312
msgid "see link:kafka-schema-registry-avro[Using Apache Kafka with Schema Registry and Avro] for more information about using Confluent or Apicurio Registry libraries"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1313
msgid "classes for which a subclass of `ObjectMapperSerializer` / `ObjectMapperDeserializer` is present, as described in <<jackson-serialization>>"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1314
msgid "it is technically not needed to subclass `ObjectMapperSerializer`, but in such case, autodetection isn't possible"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1315
msgid "classes for which a subclass of `JsonbSerializer` / `JsonbDeserializer` is present, as described in <<jsonb-serialization>>"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1316
msgid "it is technically not needed to subclass `JsonbSerializer`, but in such case, autodetection isn't possible"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1318
msgid "If a serializer/deserializer is set by configuration, it won't be replaced by the autodetection."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1321
msgid "In case you have any issues with serializer autodetection, you can switch it off completely by setting `quarkus.reactive-messaging.kafka.serializer-autodetection.enabled=false`.  If you find you need to do this, please file a bug in the link:https://github.com/quarkusio/quarkus/issues[Quarkus issue tracker] so we can fix whatever problem you have."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1322
#, no-wrap
msgid "Using Schema Registry"
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1327
#, no-wrap
msgid "Health Checks"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1331
msgid "Quarkus provides several health checks for Kafka.  These checks are used in combination with the `quarkus-smallrye-health` extension."
msgstr "Quarkusは、Kafkaのヘルスチェックをいくつか提供しています。これらのチェックは、 `quarkus-smallrye-health` エクステンションと組み合わせて使用します。"

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1332
#, no-wrap
msgid "Kafka Broker Readiness Check"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1337
#, fuzzy
#| msgid "When using the `quarkus-kafka` extension, you can enable _readiness_ health check by setting the `quarkus.kafka.health.enabled` property to `true` in your `application.properties`.  This check reports the status of the interaction with a _default_ Kafka broker (configured using `kafka.bootstrap.servers`).  That check requires an _admin connection_ with the Kafka broker.  This check is disabled by default.  If enabled, when you access the `/q/health/ready` endpoint of your application, you will have information about the connection validation status."
msgid "When using the `quarkus-kafka-client` extension, you can enable _readiness_ health check by setting the `quarkus.kafka.health.enabled` property to `true` in your `application.properties`.  This check reports the status of the interaction with a _default_ Kafka broker (configured using `kafka.bootstrap.servers`).  It requires an _admin connection_ with the Kafka broker, and it is disabled by default.  If enabled, when you access the `/q/health/ready` endpoint of your application, you will have information about the connection validation status."
msgstr "`quarkus-kafka` エクステンションを使用している場合、 `application.properties` で `quarkus.kafka.health.enabled` プロパティを `true` に設定することで、 _Readinessヘルスチェック_ を有効にすることができます。このチェックでは、 _デフォルトの_ Kafkaブローカー（ `kafka.bootstrap.servers` を使用して構成）との相互作用の状態が報告されます。そのチェックには、Kafka ブローカーとの _admin接続_ が必要です。このチェックは、デフォルトでは無効になっています。有効にすると、アプリケーションの `/q/health/ready` エンドポイントにアクセスしたときに、接続検証のステータスに関する情報が得られます。"

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1338
#, no-wrap
msgid "Kafka Reactive Messaging Health Checks"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1340
msgid "When using Reactive Messaging and the Kafka connector, each configured channel (incoming or outgoing) provides _startup_, _liveness_ and _readiness_ checks."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1342
msgid "The _startup_ check verifies that the communication with Kafka cluster is established."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1343
msgid "The _liveness_ check captures any unrecoverable failure happening during the communication with Kafka."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1344
msgid "The _readiness_ check verifies that the Kafka connector is ready to consume/produce messages to the configured Kafka topics."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1346
msgid "For each channel, you can disable the checks using:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1350
#, no-wrap
msgid "# Disable both liveness and readiness checks with `health-enabled=false`:\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1355
#, no-wrap
msgid ""
"# Incoming channel (receiving records form Kafka)\n"
"mp.messaging.incoming.your-channel.health-enabled=false\n"
"# Outgoing channel (writing records to Kafka)\n"
"mp.messaging.outgoing.your-channel.health-enabled=false\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1357
#, no-wrap
msgid "# Disable only the readiness check with `health-readiness-enabled=false`:\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1360
#, no-wrap
msgid ""
"mp.messaging.incoming.your-channel.health-readiness-enabled=false\n"
"mp.messaging.outgoing.your-channel.health-readiness-enabled=false\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1364
#, fuzzy
#| msgid "You can configure the `bootstrap.servers` for each channel. Defaults is `kafka.bootstrap.servers`."
msgid "You can configure the `bootstrap.servers` for each channel using `mp.messaging.incoming|outgoing.$channel.bootstrap.servers` property.  Default is `kafka.bootstrap.servers`."
msgstr "各チャンネルの `bootstrap.servers` を設定することができます。デフォルトは `kafka.bootstrap.servers` です。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1368
#, fuzzy
#| msgid "Reactive Messaging readiness check offers two strategies.  The default strategy verifies that an active connection is established with the broker.  This approach is not intrusive as it's based on built-in metrics."
msgid "Reactive Messaging _startup_ and _readiness_ checks offer two strategies.  The default strategy verifies that an active connection is established with the broker.  This approach is not intrusive as it's based on built-in Kafka client metrics."
msgstr "Reactive Messaging のReadinessチェックには2つのストラテジーがあります。デフォルトの方法では、ブローカーとの間にアクティブな接続が確立されているかどうかを確認します。この方法は、組み込みのメトリクスに基づいているため、邪魔にはなりません。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1372
msgid "Using the `health-topic-verification-enabled=true` attribute, _startup_ probe uses an _admin client_ to check for the list of topics.  Whereas the _readiness_ probe for an incoming channel checks that at least one partition is assigned for consumption, and for an outgoing channel checks that the topic used by the producer exist in the broker."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1375
msgid "Note that to achieve this, an _admin connection_ is required.  You can adjust the timeout for topic verification calls to the broker using the `health-topic-verification-timeout` configuration."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1376
#, no-wrap
msgid "Kafka Streams"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1379
msgid "This is described in a dedicated guide: link:kafka-streams[Using Apache Kafka Streams]."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1380
#, no-wrap
msgid "Using Snappy for message compression"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1383
msgid "On _outgoing_ channels, you can enable Snappy compression by setting the `compression.type` attribute to `snappy`:"
msgstr "_outgoing_ チャンネルでは、 `compression.type` 属性を `snappy` に設定することで、Snappy 圧縮を有効にすることができます。"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1387
#, no-wrap
msgid "mp.messaging.outgoing.fruit-out.compression.type=snappy\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1391
msgid "In JVM mode, it will work out of the box.  However, to compile your application to a native executable, you need to:"
msgstr "JVMモードでは、変更なしで動作します。しかし、アプリケーションをネイティブ実行ファイルにコンパイルするには、以下のことが必要です。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1393
msgid "Uses GraalVM 21.+"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1394
msgid "Add `quarkus.kafka.snappy.enabled=true` to your `application.properties`"
msgstr "`application.properties` に `quarkus.kafka.snappy.enabled=true`を追加"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1396
msgid "In native mode, Snappy is disabled by default as the use of Snappy requires embedding a native library and unpacking it when the application starts."
msgstr "ネイティブモードでは、Snappyはデフォルトで無効になっています。Snappyを使用するには、ネイティブライブラリを埋め込み、アプリケーションの起動時にそれを解凍する必要があるからです。"

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1397
#, no-wrap
msgid "Authentication with OAuth"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1401
msgid "If your Kafka broker uses OAuth as authentication mechanism, you need to configure the Kafka consumer to enable this authentication process.  First, add the following dependency to your application:"
msgstr "Kafka ブローカーが認証メカニズムとして OAuth を使用している場合は、この認証プロセスを有効にするために Kafka コンシューマーを設定する必要があります。まず、以下の依存関係をアプリケーションに追加します。"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1408
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.strimzi</groupId>\n"
"    <artifactId>kafka-oauth-client</artifactId>\n"
"</dependency>\n"
msgstr ""
"<dependency>\n"
"    <groupId>io.strimzi</groupId>\n"
"    <artifactId>kafka-oauth-client</artifactId>\n"
"</dependency>\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1412
msgid "This dependency provides the callback handler required to handle the OAuth workflow.  Then, in the `application.properties`, add:"
msgstr "この依存関係は、OAuth ワークフローを処理するために必要なコールバックハンドラーを提供します。そして、`application.properties` で追加します。"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1422
#, no-wrap
msgid ""
"mp.messaging.connector.smallrye-kafka.security.protocol=SASL_PLAINTEXT\n"
"mp.messaging.connector.smallrye-kafka.sasl.mechanism=OAUTHBEARER\n"
"mp.messaging.connector.smallrye-kafka.sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \\\n"
"  oauth.client.id=\"team-a-client\" \\\n"
"  oauth.client.secret=\"team-a-client-secret\" \\\n"
"  oauth.token.endpoint.uri=\"http://keycloak:8080/auth/realms/kafka-authz/protocol/openid-connect/token\" ;\n"
"mp.messaging.connector.smallrye-kafka.sasl.login.callback.handler.class=io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler\n"
msgstr ""
"mp.messaging.connector.smallrye-kafka.security.protocol=SASL_PLAINTEXT\n"
"mp.messaging.connector.smallrye-kafka.sasl.mechanism=OAUTHBEARER\n"
"mp.messaging.connector.smallrye-kafka.sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \\\n"
"  oauth.client.id=\"team-a-client\" \\\n"
"  oauth.client.secret=\"team-a-client-secret\" \\\n"
"  oauth.token.endpoint.uri=\"http://keycloak:8080/auth/realms/kafka-authz/protocol/openid-connect/token\" ;\n"
"mp.messaging.connector.smallrye-kafka.sasl.login.callback.handler.class=io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1424
#, no-wrap
msgid "quarkus.ssl.native=true\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1427
msgid "Update the `oauth.client.id`, `oauth.client.secret` and `oauth.token.endpoint.uri` values."
msgstr "`oauth.client.id`、`oauth.client.secret`、`oauth.token.endpoint.uri` の値を更新します。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1429
msgid "OAuth authentication works for both JVM and native modes. Since SSL in not enabled by default in native mode, `quarkus.ssl.native=true` must be added to support JaasClientOauthLoginCallbackHandler, which uses SSL. (See the xref:native-and-ssl.adoc[Using SSL with Native Executables] guide for more details.)"
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1430
#, no-wrap
msgid "Testing a Kafka application"
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1432
#, no-wrap
msgid "Testing without a broker"
msgstr "ブローカーなしでのテスト"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1436
msgid "It can be useful to test the application without having to start a Kafka broker.  To achieve this, you can _switch_ the channels managed by the Kafka connector to _in-memory_."
msgstr "Kafka ブローカーを起動しなくてもアプリケーションをテストできるのは便利です。これを行うには、Kafka コネクターで管理しているチャンネルを _インメモリー_ に _切り替え_ できます。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1438
msgid "This approach only works for JVM tests. It cannot be used for native tests (because they do not support injection)."
msgstr "このアプローチは、JVM テストでのみ機能します。インジェクションには対応していないため、ネイティブテストには使用できません。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1440
msgid "First, add the following dependency to your application:"
msgstr "まず、以下の依存関係をアプリケーションに追加します。"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1448
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.smallrye.reactive</groupId>\n"
"    <artifactId>smallrye-reactive-messaging-in-memory</artifactId>\n"
"    <scope>test</scope>\n"
"</dependency>\n"
msgstr ""
"<dependency>\n"
"    <groupId>io.smallrye.reactive</groupId>\n"
"    <artifactId>smallrye-reactive-messaging-in-memory</artifactId>\n"
"    <scope>test</scope>\n"
"</dependency>\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1451
msgid "Then, create a Quarkus Test Resource as follows:"
msgstr "そして、以下のように Quarkus Test Resource を作成します。"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1455
#, no-wrap
msgid "public class KafkaTestResourceLifecycleManager implements QuarkusTestResourceLifecycleManager {\n"
msgstr "public class KafkaTestResourceLifecycleManager implements QuarkusTestResourceLifecycleManager {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1465
#, no-wrap
msgid ""
"    @Override\n"
"    public Map<String, String> start() {\n"
"        Map<String, String> env = new HashMap<>();\n"
"        Map<String, String> props1 = InMemoryConnector.switchIncomingChannelsToInMemory(\"orders\");  // <1>\n"
"        Map<String, String> props2 = InMemoryConnector.switchOutgoingChannelsToInMemory(\"queue\");   // <2>\n"
"        env.putAll(props1);\n"
"        env.putAll(props2);\n"
"        return env;  // <3>\n"
"    }\n"
msgstr ""
"    @Override\n"
"    public Map<String, String> start() {\n"
"        Map<String, String> env = new HashMap<>();\n"
"        Map<String, String> props1 = InMemoryConnector.switchIncomingChannelsToInMemory(\"orders\");  // <1>\n"
"        Map<String, String> props2 = InMemoryConnector.switchOutgoingChannelsToInMemory(\"queue\");   // <2>\n"
"        env.putAll(props1);\n"
"        env.putAll(props2);\n"
"        return env;  // <3>\n"
"    }\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1471
#, no-wrap
msgid ""
"    @Override\n"
"    public void stop() {\n"
"        InMemoryConnector.clear();  // <4>\n"
"    }\n"
"}\n"
msgstr ""
"    @Override\n"
"    public void stop() {\n"
"        InMemoryConnector.clear();  // <4>\n"
"    }\n"
"}\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1473
msgid "Switch the incoming channel \"orders\" (expecting messages from Kafka) to in-memory."
msgstr "(Kafka からのメッセージが想定される) 受信チャンネル \"order\" をインメモリーに切り替えます。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1474
msgid "Switch the outgoing channel \"queue\" (writing messages to Kafka) to in-memory."
msgstr "送信チャネル \"キュー\" (Kafka へのメッセージの書き込み) をインメモリーに切り替えます。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1475
msgid "Builds and returns a `Map` containing all the properties required to configure the application to use in-memory channels."
msgstr "インメモリーチャネルを使用するためのアプリケーション設定に必要なすべてのプロパティを含む `Map` をビルドして返します。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1476
msgid "When the test stops, clear the `InMemoryConnector` (discard all the received and sent messages)"
msgstr "テストが停止したら、`InMemoryConnector` をクリアします (受信したメッセージと送信したメッセージをすべて破棄してください)。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1478
msgid "Create a Quarkus Test using the test resource created above:"
msgstr "上記で作成したテストリソースを使用して Quarkus テストを作成します。"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1484
#, no-wrap
msgid ""
"@QuarkusTest\n"
"@QuarkusTestResource(KafkaTestResourceLifecycleManager.class)\n"
"class BaristaTest {\n"
msgstr ""
"@QuarkusTest\n"
"@QuarkusTestResource(KafkaTestResourceLifecycleManager.class)\n"
"class BaristaTest {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1487
#, fuzzy, no-wrap
#| msgid ""
#| "    @Inject @Any\n"
#| "    InMemoryConnector connector; // <1>\n"
msgid ""
"    @Inject\n"
"    InMemoryConnector connector; // <1>\n"
msgstr ""
"    @Inject @Any\n"
"    InMemoryConnector connector; // <1>\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1492
#, no-wrap
msgid ""
"    @Test\n"
"    void testProcessOrder() {\n"
"        InMemorySource<Order> orders = connector.source(\"orders\"); // <2>\n"
"        InMemorySink<Beverage> queue = connector.sink(\"queue\");    // <3>\n"
msgstr ""
"    @Test\n"
"    void testProcessOrder() {\n"
"        InMemorySource<Order> orders = connector.source(\"orders\"); // <2>\n"
"        InMemorySink<Beverage> queue = connector.sink(\"queue\");    // <3>\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1497
#, no-wrap
msgid ""
"        Order order = new Order();\n"
"        order.setProduct(\"coffee\");\n"
"        order.setName(\"Coffee lover\");\n"
"        order.setOrderId(\"1234\");\n"
msgstr ""
"        Order order = new Order();\n"
"        order.setProduct(\"coffee\");\n"
"        order.setName(\"Coffee lover\");\n"
"        order.setOrderId(\"1234\");\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1499
#, no-wrap
msgid "        orders.send(order);  // <4>\n"
msgstr "        orders.send(order);  // <4>\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1501
#, no-wrap
msgid "        await().<List<? extends Message<Beverage>>>until(queue::received, t -> t.size() == 1); // <5>\n"
msgstr "        await().<List<? extends Message<Beverage>>>until(queue::received, t -> t.size() == 1); // <5>\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1508
#, no-wrap
msgid ""
"        Beverage queuedBeverage = queue.received().get(0).getPayload();\n"
"        Assertions.assertEquals(Beverage.State.READY, queuedBeverage.getPreparationState());\n"
"        Assertions.assertEquals(\"coffee\", queuedBeverage.getBeverage());\n"
"        Assertions.assertEquals(\"Coffee lover\", queuedBeverage.getCustomer());\n"
"        Assertions.assertEquals(\"1234\", queuedBeverage.getOrderId());\n"
"    }\n"
msgstr ""
"        Beverage queuedBeverage = queue.received().get(0).getPayload();\n"
"        Assertions.assertEquals(Beverage.State.READY, queuedBeverage.getPreparationState());\n"
"        Assertions.assertEquals(\"coffee\", queuedBeverage.getBeverage());\n"
"        Assertions.assertEquals(\"Coffee lover\", queuedBeverage.getCustomer());\n"
"        Assertions.assertEquals(\"1234\", queuedBeverage.getOrderId());\n"
"    }\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1512
msgid "Inject the in-memory connector in your test class."
msgstr "テストクラスにインメモリーコネクタ－を挿入します。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1513
msgid "Retrieve the incoming channel (`orders`) - the channel must have been switched to in-memory in the test resource."
msgstr "受信チャンネルを取得します (`orders`) - テストリソース内でチャンネルがインメモリーに切り替えられている必要があります。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1514
msgid "Retrieve the outgoing channel (`queue`) - the channel must have been switched to in-memory in the test resource."
msgstr "送信チャネルを取得します (`queue`) - テストリソース内でチャネルがインメモリーに切り替えられている必要があります。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1515
msgid "Use the `send` method to send a message to the `orders` channel. So, the application will process this message."
msgstr "`send` メソッドを使用して、`orders` チャンネルにメッセージを送信します。つまり、アプリケーションはこのメッセージを処理します。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1516
msgid "Use the `received` method to check the messages produced by the application."
msgstr "アプリケーションが生成するメッセージを確認するには、`received` メソッドを使用します。"

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1517
#, no-wrap
msgid "Starting Kafka in a test resource"
msgstr "テストリソースでの Kafka の起動"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1521
msgid "Alternatively, you can start a Kafka broker in a test resource.  The following snippet shows a test resource starting a Kafka broker using https://www.testcontainers.org/modules/kafka/[Testcontainers]:"
msgstr "あるいは、テストリソースで Kafka ブローカを起動することもできます。次のスニペットは、 https://www.testcontainers.org/modules/kafka/[Testcontainers] を使用して Kafka ブローカを起動するテストリソースを示しています。"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1525
#, no-wrap
msgid "public class KafkaResource implements QuarkusTestResourceLifecycleManager {\n"
msgstr "public class KafkaResource implements QuarkusTestResourceLifecycleManager {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1527
#, no-wrap
msgid "    private final KafkaContainer kafka = new KafkaContainer();\n"
msgstr "    private final KafkaContainer kafka = new KafkaContainer();\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1533
#, no-wrap
msgid ""
"    @Override\n"
"    public Map<String, String> start() {\n"
"        kafka.start();\n"
"        return Collections.singletonMap(\"kafka.bootstrap.servers\", kafka.getBootstrapServers());  // <1>\n"
"    }\n"
msgstr ""
"    @Override\n"
"    public Map<String, String> start() {\n"
"        kafka.start();\n"
"        return Collections.singletonMap(\"kafka.bootstrap.servers\", kafka.getBootstrapServers());  // <1>\n"
"    }\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1539
#, no-wrap
msgid ""
"    @Override\n"
"    public void stop() {\n"
"        kafka.close();\n"
"    }\n"
"}\n"
msgstr ""
"    @Override\n"
"    public void stop() {\n"
"        kafka.close();\n"
"    }\n"
"}\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1541
msgid "Configure the Kafka bootstrap location, so the application connects to this broker."
msgstr "アプリケーションがこのブローカーに接続するように、Kafka ブートストラップの場所を設定します。"

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1545
#, no-wrap
msgid "Kubernetes Service Bindings"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1550
msgid "Quarkus Kafka extension supports link:deploying-to-kubernetes[Service Binding Specification for Kubernetes].  You can enable this by adding the `quarkus-kubernetes-service-binding` extension to your application."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1552
msgid "When running in appropriately configured Kubernetes clusters, Kafka extension will pull its Kafka broker connection configuration from the service binding available inside the cluster, without the need for user configuration."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1554
#, fuzzy, no-wrap
#| msgid "Configuration"
msgid "Configuration Reference"
msgstr "設定"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1558
#, fuzzy
#| msgid "More details about the SmallRye Reactive Messaging configuration can be found in the https://smallrye.io/smallrye-reactive-messaging/smallrye-reactive-messaging/2.8/kafka/kafka.html[SmallRye Reactive Messaging - Kafka Connector Documentation].  The most important attributes are listed in the tables below:"
msgid "More details about the SmallRye Reactive Messaging configuration can be found in the https://smallrye.io/smallrye-reactive-messaging/smallrye-reactive-messaging/3.6/kafka/kafka.html[SmallRye Reactive Messaging - Kafka Connector Documentation].  The most important attributes are listed in the tables below:"
msgstr "SmallRye Reactive Messagingの設定についての詳細は、 link:https://smallrye.io/smallrye-reactive-messaging/smallrye-reactive-messaging/2.8/kafka/kafka.html[SmallRye Reactive Messaging - Kafka Connector Documentation]に記載されています。最も重要な属性を以下の表に示します。"

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1559
#, no-wrap
msgid "Incoming channel configuration (polling from Kafka)"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1562
#: upstream/_versions/main/guides/kafka.adoc:1580
msgid "The following attributes are configured using:"
msgstr "以下の属性は以下のように設定します:"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1566
#, no-wrap
msgid "mp.messaging.incoming.your-channel-name.attribute=value\n"
msgstr "mp.messaging.incoming.your-channel-name.attribute=value\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1569
#: upstream/_versions/main/guides/kafka.adoc:1588
msgid "Some properties have aliases which can be configured globally:"
msgstr "一部のプロパティには、グローバルに設定可能なエイリアスがあります。"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1573
#: upstream/_versions/main/guides/kafka.adoc:1592
#, no-wrap
msgid "kafka.bootstrap.servers=...\n"
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1577
#, no-wrap
msgid "Outgoing channel configuration (writing to Kafka)"
msgstr "outgoingチャンネルの設定（Kafkaへの書き込み)"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1585
#, no-wrap
msgid "mp.messaging.outgoing.your-channel-name.attribute=value\n"
msgstr "mp.messaging.outgoing.your-channel-name.attribute=value\n"

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1596
#, no-wrap
msgid "Integrating with Kafka - Common patterns"
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1598
#, no-wrap
msgid "Writing to Kafka from an HTTP endpoint"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1601
msgid "To send messages to Kafka from an HTTP endpoint, inject an `Emitter` (or a `MutinyEmitter`) in your endpoint:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1605
#: upstream/_versions/main/guides/kafka.adoc:1653
#: upstream/_versions/main/guides/kafka.adoc:1694
#: upstream/_versions/main/guides/kafka.adoc:1712
#: upstream/_versions/main/guides/kafka.adoc:1743
#: upstream/_versions/main/guides/kafka.adoc:1775
#: upstream/_versions/main/guides/kafka.adoc:1794
#: upstream/_versions/main/guides/kafka.adoc:1829
#: upstream/_versions/main/guides/kafka.adoc:1872
#: upstream/_versions/main/guides/kafka.adoc:1913
#, fuzzy, no-wrap
#| msgid "package org.acme.kafka;\n"
msgid "package org.acme;\n"
msgstr "package org.acme.kafka;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1607
#: upstream/_versions/main/guides/kafka.adoc:1655
#: upstream/_versions/main/guides/kafka.adoc:1874
#, fuzzy, no-wrap
#| msgid "import javax.enterprise.context.ApplicationScoped;\n"
msgid "import java.util.concurrent.CompletionStage;\n"
msgstr "import javax.enterprise.context.ApplicationScoped;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1612
#: upstream/_versions/main/guides/kafka.adoc:1660
#, fuzzy, no-wrap
#| msgid ""
#| "import javax.inject.Inject;\n"
#| "import javax.ws.rs.POST;\n"
#| "import javax.ws.rs.Path;\n"
#| "import javax.ws.rs.Consumes;\n"
#| "import javax.ws.rs.core.MediaType;\n"
msgid ""
"import javax.ws.rs.POST;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.Produces;\n"
"import javax.ws.rs.core.MediaType;\n"
msgstr ""
"import javax.inject.Inject;\n"
"import javax.ws.rs.POST;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.Consumes;\n"
"import javax.ws.rs.core.MediaType;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1618
#: upstream/_versions/main/guides/kafka.adoc:1668
#: upstream/_versions/main/guides/kafka.adoc:1884
#, fuzzy, no-wrap
#| msgid ""
#| "@Path(\"/prices\")\n"
#| "public class PriceResource {\n"
msgid ""
"@Path(\"/\")\n"
"public class ResourceSendingToKafka {\n"
msgstr ""
"@Path(\"/prices\")\n"
"public class PriceResource {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1620
#, no-wrap
msgid "    @Channel(\"kafka\") Emitter<String> emitter;          // <1>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1627
#, fuzzy, no-wrap
#| msgid ""
#| "    @POST\n"
#| "    @Consumes(MediaType.TEXT_PLAIN)\n"
#| "    public void addPrice(Double price) {\n"
#| "        priceEmitter.send(price);\n"
#| "    }\n"
#| "}\n"
msgid ""
"    @POST\n"
"    @Produces(MediaType.TEXT_PLAIN)\n"
"    public CompletionStage<Void> send(String payload) { // <2>\n"
"        return emitter.send(payload);                   // <3>\n"
"    }\n"
"}\n"
msgstr ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public void addPrice(Double price) {\n"
"        priceEmitter.send(price);\n"
"    }\n"
"}\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1629
msgid "Inject an `Emitter<String>`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1630
#, fuzzy
#| msgid "The new `Emitter.send` method returns a `CompletionStage` completed when the produced message is acknowledged."
msgid "The HTTP method receives the payload and returns a `CompletionStage` completed when the message is written to Kafka"
msgstr "新しい `Emitter.send` メソッドは、生成されたメッセージが確認されると、`CompletionStage` の完了を返します。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1631
msgid "Send the message to Kafka, the `send` method returns a `CompletionStage`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1634
msgid "The endpoint sends the passed payload (from a `POST` HTTP request) to the emitter.  The emitter's channel is mapped to a Kafka topic in the `application.properties` file:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1639
#, no-wrap
msgid ""
"mp.messaging.outgoing.kafka.connector=smallrye-kafka\n"
"mp.messaging.outgoing.kafka.topic=my-topic\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1645
msgid "The endpoint returns a `CompletionStage` indicating the asynchronous nature of the method.  The `emitter.send` method returns a `CompletionStage<Void>` .  The returned future is completed when the message has been written to Kafka.  If the writing fails, the returned `CompletionStage` is completed exceptionally."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1647
msgid "If the endpoint does not return a `CompletionStage`, the HTTP response may be written before the message is sent to Kafka, and so failures won't be reported to the user."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1649
msgid "If you need to send a Kafka record, use:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1665
#, fuzzy, no-wrap
#| msgid "`io.smallrye.reactive.messaging.annotations.Blocking`"
msgid "import io.smallrye.reactive.messaging.kafka.Record;\n"
msgstr "`io.smallrye.reactive.messaging.annotations.Blocking`"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1670
#, no-wrap
msgid "    @Channel(\"kafka\") Emitter<Record<String,String>> emitter;  // <1>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1678
#, fuzzy, no-wrap
#| msgid ""
#| "    @POST\n"
#| "    @Consumes(MediaType.TEXT_PLAIN)\n"
#| "    public void addPrice(Double price) {\n"
#| "        priceEmitter.send(price);\n"
#| "    }\n"
#| "}\n"
msgid ""
"    @POST\n"
"    @Produces(MediaType.TEXT_PLAIN)\n"
"    public CompletionStage<Void> send(String payload) {\n"
"        return emitter.send(Record.of(\"my-key\", payload));    // <2>\n"
"    }\n"
"}\n"
msgstr ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public void addPrice(Double price) {\n"
"        priceEmitter.send(price);\n"
"    }\n"
"}\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1680
msgid "Note the usage of an `Emitter<Record<K, V>>`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1681
msgid "Create the record using `Record.of(k, v)`"
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1682
#, no-wrap
msgid "Persisting Kafka messages with Hibernate with Panache"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1685
msgid "To persist objects received from Kafka into a database, you can use Hibernate with Panache."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1687
msgid "If you use Hibernate Reactive, look at <<persisting-kafka-messages-with-hibernate-reactive>>."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1690
#: upstream/_versions/main/guides/kafka.adoc:1771
msgid "Let's imagine you receive `Fruit` objects.  For simplicity purposes, our `Fruit` class is pretty simple:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1696
#: upstream/_versions/main/guides/kafka.adoc:1777
#, no-wrap
msgid "import javax.persistence.Entity;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1698
#, no-wrap
msgid "import io.quarkus.hibernate.orm.panache.PanacheEntity;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1701
#: upstream/_versions/main/guides/kafka.adoc:1782
#, fuzzy, no-wrap
#| msgid ""
#| "@Path(\"/fruits\")\n"
#| "public class FruitResource {\n"
msgid ""
"@Entity\n"
"public class Fruit extends PanacheEntity {\n"
msgstr ""
"@Path(\"/fruits\")\n"
"public class FruitResource {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1703
#: upstream/_versions/main/guides/kafka.adoc:1784
#, fuzzy, no-wrap
#| msgid ""
#| "    public String name;\n"
#| "    public int price;\n"
msgid "    public String name;\n"
msgstr ""
"    public String name;\n"
"    public int price;\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1708
#: upstream/_versions/main/guides/kafka.adoc:1790
msgid "To consume `Fruit` instances stored on a Kafka topic, and persist them into a database, you can use the following approach:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1719
#, fuzzy, no-wrap
#| msgid "`io.smallrye.common.annotation.Blocking`"
msgid "import io.smallrye.common.annotation.Blocking;\n"
msgstr "`io.smallrye.common.annotation.Blocking`"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1722
#, fuzzy, no-wrap
#| msgid ""
#| "@ApplicationScoped\n"
#| "public class PriceStorage {\n"
msgid ""
"@ApplicationScoped\n"
"public class FruitConsumer {\n"
msgstr ""
"@ApplicationScoped\n"
"public class PriceStorage {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1730
#, no-wrap
msgid ""
"    @Incoming(\"fruits\")                                     // <1>\n"
"    @Transactional                                          // <2>\n"
"    @Blocking                                               // <3>\n"
"    public void persistFruits(Fruit fruit) {                // <4>\n"
"        fruit.persist();                                    // <5>\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1732
msgid "Configuring the incoming channel. This channel reads from Kafka."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1733
msgid "As we are writing in a database, we must be in a transaction. This annotation starts a new transaction and commits it when the method returns."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1734
msgid "Writing to a database using classic Hibernate is blocking. So, you must tell to Quarkus that the method must be called on a worker thread you can block (and not an I/O thread)."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1735
msgid "The method receives each Fruit. Note that you would need a deserializer to reconstruct the Fruit instances from the Kafka records."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1736
msgid "Persist the received `fruit` object."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1739
msgid "As mentioned in <4>, you need a deserializer that can create a `Fruit` from the record.  This can be done using a Jackson deserializer:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1754
#: upstream/_versions/main/guides/kafka.adoc:1840
msgid "The associated configuration would be:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1759
#: upstream/_versions/main/guides/kafka.adoc:1845
#, fuzzy, no-wrap
#| msgid ""
#| "# Configure the Kafka sink (we write to it)\n"
#| "mp.messaging.outgoing.generated-price.connector=smallrye-kafka\n"
#| "mp.messaging.outgoing.generated-price.topic=prices\n"
#| "mp.messaging.outgoing.generated-price.value.serializer=org.apache.kafka.common.serialization.IntegerSerializer\n"
msgid ""
"mp.messaging.incoming.fruits.connector=smallrye-kafka\n"
"mp.messaging.incoming.fruits.value.deserializer=org.acme.FruitDeserializer\n"
msgstr ""
"# Configure the Kafka sink (we write to it)\n"
"mp.messaging.outgoing.generated-price.connector=smallrye-kafka\n"
"mp.messaging.outgoing.generated-price.topic=prices\n"
"mp.messaging.outgoing.generated-price.value.serializer=org.apache.kafka.common.serialization.IntegerSerializer\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1763
#: upstream/_versions/main/guides/kafka.adoc:1849
msgid "Check <<jackson-serialization>> for more detail about the usage of Jackson with Kafka.  You can also use Avro."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1765
#, no-wrap
msgid "Persisting Kafka messages with Hibernate Reactive"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1768
msgid "To persist objects received from Kafka into a database, you can use Hibernate Reactive with Panache."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1779
#, no-wrap
msgid "import io.quarkus.hibernate.reactive.panache.PanacheEntity;  // <1>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1788
msgid "Make sure to use the reactive variant"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1801
#, no-wrap
msgid ""
"import io.quarkus.hibernate.reactive.panache.Panache;\n"
"import io.smallrye.mutiny.Uni;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1804
#, fuzzy, no-wrap
#| msgid ""
#| "@ApplicationScoped\n"
#| "public class PriceStorage {\n"
msgid ""
"@ApplicationScoped\n"
"public class FruitStore {\n"
msgstr ""
"@ApplicationScoped\n"
"public class PriceStorage {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1812
#, no-wrap
msgid ""
"    @Incoming(\"fruits\")\n"
"    public Uni<Void> persist(Fruit fruit) {\n"
"        return Panache.withTransaction(() ->  // <1>\n"
"            fruit.persist()                   // <2>\n"
"                .map(persisted -> null)       // <3>\n"
"        );\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1816
msgid "Instruct Panache to run the given (asynchronous) action in a transaction. The transaction completes when the action completes."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1817
msgid "Persist the entity. It returns a `Uni<Fruit>`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1818
msgid "Switch back to a `Uni<Void>`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1822
msgid "Unlike with _classic_ Hibernate, you can't use `@Transactional`.  Instead, we use `Panache.withTransaction` and persist our entity.  The `map` is used to return a `Uni<Void>` and not a `Uni<Fruit>`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1825
msgid "You need a deserializer that can create a `Fruit` from the record.  This can be done using a Jackson deserializer:"
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1850
#, no-wrap
msgid "Writing entities managed by Hibernate to Kafka"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1853
msgid "Let's imagine the following process:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1855
msgid "You receive an HTTP request with a payload,"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1856
msgid "You create an Hibernate entity instance from this payload,"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1857
msgid "You persist that entity into a database,"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1858
msgid "You send the entity to a Kafka topic"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1860
msgid "If you use Hibernate Reactive, look at <<writing-entities-managed-by-hibernate-reactive-to-kafka>>."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1866
msgid "Because we write to a database, we must run this method in a transaction.  Yet, sending the entity to Kafka happens asynchronously.  The operation returns a `CompletionStage` (or a `Uni` if you use a `MutinyEmitter`) reporting when the operation completes.  We must be sure that the transaction is still running until the object is written.  Otherwise, you may access the object outside the transaction, which is not allowed."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1868
msgid "To implement this process, you need the following approach:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1878
#, fuzzy, no-wrap
#| msgid ""
#| "import javax.inject.Inject;\n"
#| "import javax.ws.rs.POST;\n"
#| "import javax.ws.rs.Path;\n"
#| "import javax.ws.rs.Consumes;\n"
#| "import javax.ws.rs.core.MediaType;\n"
msgid ""
"import javax.transaction.Transactional;\n"
"import javax.ws.rs.POST;\n"
"import javax.ws.rs.Path;\n"
msgstr ""
"import javax.inject.Inject;\n"
"import javax.ws.rs.POST;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.Consumes;\n"
"import javax.ws.rs.core.MediaType;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1886
#, fuzzy, no-wrap
#| msgid "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"
msgid "    @Channel(\"kafka\") Emitter<Fruit> emitter;\n"
msgstr "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1895
#, no-wrap
msgid ""
"    @POST\n"
"    @Path(\"/fruits\")\n"
"    @Transactional                                                      // <1>\n"
"    public CompletionStage<Void> storeAndSendToKafka(Fruit fruit) {     // <2>\n"
"        fruit.persist();\n"
"        return emitter.send(fruit);                                     // <3>\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1897
msgid "As we are writing to the database, make sure we run inside a transaction"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1898
msgid "The method receives the fruit instance to persist. It returns a `CompletionStage` which is used for the transaction demarcation. The transaction is committed when the return `CompletionStage` completes. In our case, it's when the message is written to Kafka."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1899
msgid "Send the managed instance to Kafka. Make sure we wait for the message to complete before closing the transaction."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1901
#, no-wrap
msgid "Writing entities managed by Hibernate Reactive to Kafka"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1904
msgid "To send to Kafka entities managed by Hibernate Reactive, we recommend using:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1906
msgid "RESTEasy Reactive to serve HTTP requests"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1907
msgid "A `MutinyEmitter` to send message to a channel, so it can be easily integrated with the Mutiny API exposed by Hibernate Reactive or Hibernate Reactive with Panache."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1909
msgid "The following example demonstrates how to receive a payload, store it in the database using Hibernate Reactive with Panache, and send the persisted entity to Kafka:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1916
#, no-wrap
msgid ""
"import javax.ws.rs.POST;\n"
"import javax.ws.rs.Path;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1922
#, fuzzy, no-wrap
#| msgid ""
#| "import io.smallrye.mutiny.Multi;\n"
#| "import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
msgid ""
"import io.quarkus.hibernate.reactive.panache.Panache;\n"
"import io.smallrye.mutiny.Uni;\n"
"import io.smallrye.reactive.messaging.MutinyEmitter;\n"
msgstr ""
"import io.smallrye.mutiny.Multi;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1925
#, fuzzy, no-wrap
#| msgid ""
#| "@Path(\"/prices\")\n"
#| "public class PriceResource {\n"
msgid ""
"@Path(\"/\")\n"
"public class ReactiveGreetingResource {\n"
msgstr ""
"@Path(\"/prices\")\n"
"public class PriceResource {\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1927
#, fuzzy, no-wrap
#| msgid "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"
msgid "    @Channel(\"kafka\") MutinyEmitter<Fruit> emitter;     // <1>\n"
msgstr "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1937
#, no-wrap
msgid ""
"    @POST\n"
"    @Path(\"/fruits\")\n"
"    public Uni<Void> sendToKafka(Fruit fruit) {         // <2>\n"
"        return Panache.withTransaction(() ->            // <3>\n"
"            fruit.<Fruit>persist()\n"
"        )\n"
"            .chain(f -> emitter.send(f));               // <4>\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1939
msgid "Inject a `MutinyEmitter` which exposes a Mutiny API. It simplifies the integration with the Mutiny API exposed by Hibernate Reactive with Panache."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1940
msgid "The HTTP method receiving the payload returns a `Uni<Void>`. The HTTP response is written when the operation completes (the entity is persisted and written to Kafka)."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1941
msgid "We need to write the entity into the database in a transaction."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1942
msgid "Once the persist operation completes, we send the entity to Kafka. The `send` method returns a `Uni<Void>`."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1944
#, no-wrap
msgid "Streaming Kafka topics as server-sent events"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1947
msgid "Streaming a Kafka topic as server-sent events (SSE) is straightforward:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1949
msgid "You inject the channel representing the Kafka topic in your HTTP endpoint"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1950
msgid "You return that channel as a `Publisher` or a `Multi` from the HTTP method"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1952
msgid "The following code provides an example:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1957
#: upstream/_versions/main/guides/kafka.adoc:1972
#, fuzzy, no-wrap
#| msgid ""
#| "    @Inject\n"
#| "    @Channel(\"fruit-out\") Publisher<Fruit> fruits;\n"
msgid ""
"@Channel(\"fruits\")\n"
"Multi<Fruit> fruits;\n"
msgstr ""
"    @Inject\n"
"    @Channel(\"fruit-out\") Publisher<Fruit> fruits;\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1963
#, fuzzy, no-wrap
#| msgid ""
#| "    @GET\n"
#| "    @Path(\"/stream\")\n"
#| "    @Produces(MediaType.SERVER_SENT_EVENTS) // <2>\n"
#| "    @SseElementType(\"text/plain\") // <3>\n"
#| "    public Publisher<Double> stream() { // <4>\n"
#| "        return prices;\n"
#| "    }\n"
#| "}\n"
msgid ""
"@GET\n"
"@Produces(MediaType.SERVER_SENT_EVENTS)\n"
"public Multi<Fruit> stream() {\n"
"    return fruits;\n"
"}\n"
msgstr ""
"    @GET\n"
"    @Path(\"/stream\")\n"
"    @Produces(MediaType.SERVER_SENT_EVENTS) // <2>\n"
"    @SseElementType(\"text/plain\") // <3>\n"
"    public Publisher<Double> stream() { // <4>\n"
"        return prices;\n"
"    }\n"
"}\n"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1967
msgid "Some environment cuts the SSE connection when there is not enough activity.  The workaround consists of sending _ping_ messages (or empty objects) periodically."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1975
#, no-wrap
msgid ""
"@Inject\n"
"ObjectMapper mapper;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1985
#, no-wrap
msgid ""
"@GET\n"
"@Produces(MediaType.SERVER_SENT_EVENTS)\n"
"public Multi<String> stream() {\n"
"    return Multi.createBy().merging()\n"
"            .streams(\n"
"                    fruits.map(this::toJson),\n"
"                    getPingStream()\n"
"            );\n"
"}\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1990
#, fuzzy, no-wrap
#| msgid ""
#| "    @Outgoing(\"generated-price\")                        // <1>\n"
#| "    public Multi<Integer> generate() {                  // <2>\n"
#| "        return Multi.createFrom().ticks().every(Duration.ofSeconds(5))\n"
#| "                .onOverflow().drop()\n"
#| "                .map(tick -> random.nextInt(100));\n"
#| "    }\n"
msgid ""
"Multi<String> emitAPeriodicPing() {\n"
"    return Multi.createFrom().ticks().every(Duration.ofSeconds(10))\n"
"            .onItem().transform(x -> \"{}\");\n"
"}\n"
msgstr ""
"    @Outgoing(\"generated-price\")                        // <1>\n"
"    public Multi<Integer> generate() {                  // <2>\n"
"        return Multi.createFrom().ticks().every(Duration.ofSeconds(5))\n"
"                .onOverflow().drop()\n"
"                .map(tick -> random.nextInt(100));\n"
"    }\n"

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1998
#, no-wrap
msgid ""
"private String toJson(Fruit f) {\n"
"    try {\n"
"        return mapper.writeValueAsString(f);\n"
"    } catch (JsonProcessingException e) {\n"
"        throw new RuntimeException(e);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:2002
msgid "The workaround is a bit more complex as besides sending the fruits coming from Kafka, we need to send pings periodically.  To achieve this we merge the stream coming from Kafka and a periodic stream emitting `{}` every 10 seconds."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:2003
#, no-wrap
msgid "Going further"
msgstr "さらに詳しく"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:2007
msgid "This guide has shown how you can interact with Kafka using Quarkus.  It utilizes SmallRye Reactive Messaging to build data streaming applications."
msgstr "このガイドでは、Quarkus を使用して Kafka とやりとりする方法を示しました。SmallRye Reactive Messaging を利用して、データストリーミングアプリケーションを構築します。"

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:2008
#, fuzzy
#| msgid "If you want to go further check the documentation of https://smallrye.io/smallrye-reactive-messaging[SmallRye Reactive Messaging], the implementation used in Quarkus."
msgid "If you want to go further, check the documentation of https://smallrye.io/smallrye-reactive-messaging[SmallRye Reactive Messaging], the implementation used in Quarkus."
msgstr "さらに詳しく知りたい場合は、Quarkusで使用されている実装である link:https://smallrye.io/smallrye-reactive-messaging[SmallRye Reactive Messaging] のドキュメントを確認してください。"

#~ msgid "When using Reactive Messaging and the Kafka connector, each configured channel (incoming or outgoing) provides a _liveness_ and _readiness_ check.  The _liveness_ check captures any unrecoverable failure happening during the communication with Kafka.  The _readiness_ check verifies that communication with Kafka is established.  For each channel, you can disable the checks using:"
#~ msgstr "Reactive MessagingとKafkaコネクタを使用する場合、設定された各チャネル（受信または送信）は、 _Liveness_ と _Readiness_ のチェックを提供します。 _Liveness_ チェックでは、Kafkaとの通信中に発生した回復不能な障害を捕捉します。 _Readiness_ チェックでは、Kafkaとの通信が確立されていることを確認します。各チャネルでは、以下の方法でチェックを無効にすることができます。"

#, fuzzy
#~| msgid "Using the `health-readiness-topic-verification=true` attribute, you can also check the topics used by the application exist in the broker.  Note that, to achieve this, an _admin connection_ is required."
#~ msgid "Using the `health-readiness-topic-verification=true` attribute, you can also check the topics used by the application exist in the broker.  Note that to achieve this, an _admin connection_ is required."
#~ msgstr "`health-readiness-topic-verification=true` 属性を使用すると、アプリケーションが使用するトピックがブローカーに存在することも確認できます。なお、これを行うためには、 _admin接続_ が必要です。"

#~ msgid "Incoming Attributes of the 'smallrye-kafka' connector"
#~ msgstr "'smallrye-kafka' connectorのIncoming属性"

#~ msgid "Attribute (_alias_)"
#~ msgstr "属性 (_alias_)"

#~ msgid "Description"
#~ msgstr "説明"

#~ msgid "Mandatory"
#~ msgstr "必須"

#~ msgid "Default"
#~ msgstr "デフォルト"

#~ msgid ""
#~ "*bootstrap.servers*\n"
#~ "\n"
#~ "_(kafka.bootstrap.servers)_"
#~ msgstr ""
#~ "*bootstrap.servers*\n"
#~ "\n"
#~ "_(kafka.bootstrap.servers)_"

#~ msgid "false"
#~ msgstr "false"

#~ msgid "`localhost:9092`"
#~ msgstr "`localhost:9092`"

#~ msgid "*topic*"
#~ msgstr "*topic*"

#~ msgid ""
#~ "The consumed / populated Kafka topic. If neither this property nor the `topics` properties are set, the channel name is used\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "消費/投入されるKafkaトピック。このプロパティも `topics` のプロパティも設定されていない場合は、チャネル名が使用されます。\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "*health-enabled*"
#~ msgstr "*health-enabled*"

#~ msgid ""
#~ "Whether health reporting is enabled (default) or disabled\n"
#~ "\n"
#~ "Type: _boolean_"
#~ msgstr ""
#~ "ヘルスレポートが有効（デフォルト）か無効か\n"
#~ "\n"
#~ "Type: _boolean_"

#~ msgid "`true`"
#~ msgstr "`true`"

#~ msgid "*health-readiness-enabled*"
#~ msgstr "*health-readiness-enabled*"

#~ msgid ""
#~ "Whether readiness health reporting is enabled (default) or disabled\n"
#~ "\n"
#~ "Type: _boolean_"
#~ msgstr ""
#~ "レディネスレポートが有効（デフォルト）か無効か\n"
#~ "\n"
#~ "Type: _boolean_"

#~ msgid "*health-readiness-topic-verification*"
#~ msgstr "*health-readiness-topic-verification*"

#~ msgid ""
#~ "Whether the readiness check should verify that topics exist on the broker. Default to false. Enabling it requires an admin connection.\n"
#~ "\n"
#~ "Type: _boolean_"
#~ msgstr ""
#~ "ブローカにトピックが存在するかどうかをReadinessチェックで確認するかどうか。デフォルトはfalseです。これを有効にするには、admin接続が必要です。\n"
#~ "\n"
#~ "Type: _boolean_"

#~ msgid "`false`"
#~ msgstr "`false`"

#~ msgid "*health-readiness-timeout*"
#~ msgstr "*health-readiness-timeout*"

#~ msgid ""
#~ "During the readiness health check, the connector connects to the broker and retrieves the list of topics. This attribute specifies the maximum duration (in ms) for the retrieval. If exceeded, the channel is considered not-ready.\n"
#~ "\n"
#~ "Type: _long_"
#~ msgstr ""
#~ "Readinesチェックの間、コネクタはブローカーに接続し、トピックのリストを取得します。この属性では、検索にかける最大時間（ms）を指定します。これを超えると、チャネルは準備ができていないとみなされます。\n"
#~ "\n"
#~ "Type: _long_"

#~ msgid "*tracing-enabled*"
#~ msgstr "*tracing-enabled*"

#~ msgid ""
#~ "Whether tracing is enabled (default) or disabled\n"
#~ "\n"
#~ "Type: _boolean_"
#~ msgstr ""
#~ "トレースを有効（デフォルト）にするか、無効にするか\n"
#~ "\n"
#~ "Type: _boolean_"

#~ msgid "*cloud-events*"
#~ msgstr "*cloud-events*"

#~ msgid ""
#~ "Enables (default) or disables the Cloud Event support. If enabled on an _incoming_ channel, the connector analyzes the incoming records and try to create Cloud Event metadata. If enabled on an _outgoing_, the connector sends the outgoing messages as Cloud Event if the message includes Cloud Event Metadata.\n"
#~ "\n"
#~ "Type: _boolean_"
#~ msgstr ""
#~ "クラウド イベント サポートを有効（デフォルト）または無効にします。 _incoming_ チャネルで有効にすると、コネクタは受信レコードを分析し、Cloud Event メタデータの作成を試みます。 _outgoing_ 側で有効にすると、メッセージに Cloud Event Metadata が含まれている場合、コネクタはoutgoingメッセージを Cloud Event として送信します。\n"
#~ "\n"
#~ "Type: _boolean_"

#~ msgid "*topics*"
#~ msgstr "*topics*"

#~ msgid ""
#~ "A comma-separating list of topics to be consumed. Cannot be used with the `topic` or `pattern` properties\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "消費されるトピックのコンマ区切りのリスト。 `topic` または `pattern` のプロパティとは併用できません。\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "*pattern*"
#~ msgstr "*pattern*"

#~ msgid ""
#~ "Indicate that the `topic` property is a regular expression. Must be used with the `topic` property. Cannot be used with the `topics` property\n"
#~ "\n"
#~ "Type: _boolean_"
#~ msgstr ""
#~ "`topic` プロパティが正規表現であることを示す。 `topic` プロパティと併用する必要があります。 `topics` プロパティとは併用できません。\n"
#~ "\n"
#~ "Type: _boolean_"

#~ msgid "*key.deserializer*"
#~ msgstr "*key.deserializer*"

#~ msgid ""
#~ "The deserializer classname used to deserialize the record's key\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "レコードのキーをデシリアライズするために使用されるデシリアライザのクラス名\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "`org.apache.kafka.common.serialization.StringDeserializer`"
#~ msgstr "`org.apache.kafka.common.serialization.StringDeserializer`"

#~ msgid "*value.deserializer*"
#~ msgstr "*value.deserializer*"

#~ msgid ""
#~ "The deserializer classname used to deserialize the record's value\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "レコードの値のデシリアライズに使用されるデシリアライザのクラス名\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "true"
#~ msgstr "true"

#~ msgid "*fetch.min.bytes*"
#~ msgstr "*fetch.min.bytes*"

#~ msgid ""
#~ "The minimum amount of data the server should return for a fetch request. The default setting of 1 byte means that fetch requests are answered as soon as a single byte of data is available or the fetch request times out waiting for data to arrive.\n"
#~ "\n"
#~ "Type: _int_"
#~ msgstr ""
#~ "フェッチ・リクエストに対してサーバーが返すべきデータの最小量。デフォルトの1バイトの設定は、1バイトのデータが利用可能になるか、データの到着を待ってフェッチリクエストがタイムアウトするとすぐにフェッチリクエストに応答することを意味します。\n"
#~ "\n"
#~ "Type: _int_"

#~ msgid "*group.id*"
#~ msgstr "*group.id*"

#~ msgid ""
#~ "A unique string that identifies the consumer group the application belongs to.\n"
#~ "\n"
#~ "If not set, defaults to the application name as set by the `quarkus.application.name` configuration property.\n"
#~ "\n"
#~ "If that is not set either, a unique, generated id is used.\n"
#~ "It is recommended to always define a `group.id`, the automatic generation is only a convenient feature for development.\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "アプリケーションが所属するコンシューマーグループを識別するための一意の文字列。\n"
#~ "\n"
#~ "設定されていない場合、デフォルトでは、 `quarkus.application.name`構成プロパティで設定されたアプリケーション名になります。\n"
#~ "\n"
#~ "それも設定されていない場合は、生成された一意のIDが使用されます。\n"
#~ "常に `group.id` を定義することをお勧めします。自動生成は、開発用の便利機能にすぎません。\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "*enable.auto.commit*"
#~ msgstr "*enable.auto.commit*"

#~ msgid ""
#~ "If enabled, consumer's offset will be periodically committed in the background by the underlying Kafka client, ignoring the actual processing outcome of the records. It is recommended to NOT enable this setting and let Reactive Messaging handles the commit.\n"
#~ "\n"
#~ "Type: _boolean_"
#~ msgstr ""
#~ "この設定を有効にすると、コンシューマーのオフセットは、レコードの実際の処理結果を無視して、基礎となるKafkaクライアントによってバックグラウンドで定期的にコミットされます。この設定を有効にしないで、Reactive Messaging にコミットを任せることをお勧めします。\n"
#~ "\n"
#~ "Type: _boolean_"

#~ msgid "*retry*"
#~ msgstr "*retry*"

#~ msgid ""
#~ "Whether or not the connection to the broker is re-attempted in case of failure\n"
#~ "\n"
#~ "Type: _boolean_"
#~ msgstr ""
#~ "障害発生時にブローカーへの接続を再試行するかどうか\n"
#~ "\n"
#~ "Type: _boolean_"

#~ msgid "*retry-attempts*"
#~ msgstr "*retry-attempts*"

#~ msgid ""
#~ "The maximum number of reconnection before failing. -1 means infinite retry\n"
#~ "\n"
#~ "Type: _int_"
#~ msgstr ""
#~ "失敗するまでの最大再接続回数を指定します。-1は無限再試行を意味します。\n"
#~ "\n"
#~ "Type: _int_"

#~ msgid "*retry-max-wait*"
#~ msgstr "*retry-max-wait*"

#~ msgid ""
#~ "The max delay (in seconds) between 2 reconnects\n"
#~ "\n"
#~ "Type: _int_"
#~ msgstr ""
#~ "2回の再接続の間の最大遅延時間（秒）\n"
#~ "\n"
#~ "Type: _int_"

#~ msgid "*broadcast*"
#~ msgstr "*broadcast*"

#~ msgid "*auto.offset.reset*"
#~ msgstr "*auto.offset.reset*"

#~ msgid "`latest`"
#~ msgstr "`latest`"

#~ msgid "*failure-strategy*"
#~ msgstr "*failure-strategy*"

#~ msgid ""
#~ "Specify the failure strategy to apply when a message produced from a record is acknowledged negatively (nack). Values can be `fail` (default), `ignore`, or `dead-letter-queue`\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "レコードから生成されたメッセージが否定的に確認された（nack）場合に適用する失敗戦略を指定します。値は、 `fail` （デフォルト）、 `ignore` 、または `dead-letter-queue`\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "`fail`"
#~ msgstr "`fail`"

#~ msgid "*commit-strategy*"
#~ msgstr "*commit-strategy*"

#~ msgid ""
#~ "Specify the commit strategy to apply when a message produced from a record is acknowledged. Values can be `latest`, `ignore` or `throttled`. If `enable.auto.commit` is true then the default is `ignore` otherwise it is `throttled`\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "レコードから生成されたメッセージが確認されたときに適用するコミットストラテジーを指定します。値は、 `latest` 、 `ignore` 、 `throttled` のいずれかです。 `enable.auto.commit` がtrueであれば、デフォルトは `ignore` です。そうでなければ `throttled` です。\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "*throttled.unprocessed-record-max-age.ms*"
#~ msgstr "*throttled.unprocessed-record-max-age.ms*"

#~ msgid ""
#~ "While using the `throttled` commit-strategy, specify the max age in milliseconds that an unprocessed message can be before the connector is marked as unhealthy.\n"
#~ "\n"
#~ "Type: _int_"
#~ msgstr ""
#~ "`throttled` commit-strategy を使用している場合の、コネクタが不健全であるとマークされるまでの未処理メッセージの最大時間をミリ秒単位で指定します。\n"
#~ "\n"
#~ "Type: _int_"

#~ msgid "*dead-letter-queue.topic*"
#~ msgstr "*dead-letter-queue.topic*"

#~ msgid ""
#~ "When the `failure-strategy` is set to `dead-letter-queue` indicates on which topic the record is sent. Defaults is `dead-letter-topic-$channel`\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "`failure-strategy` に `dead-letter-queue` が設定されている場合、どのトピックにレコードが送信されるかを示します。デフォルトは `dead-letter-topic-$channel`\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "*dead-letter-queue.key.serializer*"
#~ msgstr "*dead-letter-queue.key.serializer*"

#~ msgid ""
#~ "When the `failure-strategy` is set to `dead-letter-queue` indicates the key serializer to use. If not set the serializer associated to the key deserializer is used\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "`failure-strategy` に `dead-letter-queue` が設定されている場合、 使用するキーシリアライザを示します。設定されていない場合は、キーデシリアライザに関連付けられたシリアライザが使用されます。\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "*dead-letter-queue.value.serializer*"
#~ msgstr "*dead-letter-queue.value.serializer*"

#~ msgid ""
#~ "When the `failure-strategy` is set to `dead-letter-queue` indicates the value serializer to use. If not set the serializer associated to the value deserializer is used\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "`failure-strategy` に `dead-letter-queue` が設定されている場合、使用する値のシリアライザを示します。設定されていない場合は、値のデシリアライザに関連付けられたシリアライザが使用されます。\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "*partitions*"
#~ msgstr "*partitions*"

#~ msgid ""
#~ "The number of partitions to be consumed concurrently. The connector creates the specified amount of Kafka consumers. It should match the number of partition of the targeted topic\n"
#~ "\n"
#~ "Type: _int_"
#~ msgstr ""
#~ "同時に消費されるパーティションの数です。コネクタは、指定された数のKafkaコンシューマーを作成します。これは、対象となるトピックのパーティション数と一致する必要があります。\n"
#~ "\n"
#~ "Type: _int_"

#~ msgid "*consumer-rebalance-listener.name*"
#~ msgstr "*consumer-rebalance-listener.name*"

#~ msgid ""
#~ "The name set in `javax.inject.Named` of a bean that implements `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener`. If set, this rebalance listener is applied to the consumer.\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "`io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` を実装するBeanの `javax.inject.Named` で設定された名前です。設定された場合、このリバランスリスナーはコンシューマーに適用されます。\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "*key-deserialization-failure-handler*"
#~ msgstr "*key-deserialization-failure-handler*"

#~ msgid ""
#~ "The name set in `javax.inject.Named` of a bean that implements `io.smallrye.reactive.messaging.kafka.DeserializationFailureHandler`. If set, deserialization failure happening when deserializing keys are delegated to this handler which may provide a fallback value.\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "`io.smallrye.reactive.messaging.kafka.DeserializationFailureHandler` を実装するBeanの `javax.inject.Named` で設定された名前です。設定されている場合、キーをデシリアライズする際に起こるデシリアライズの失敗は、フォールバック値を提供することができるこのハンドラに委ねられます。\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "*value-deserialization-failure-handler*"
#~ msgstr "*value-deserialization-failure-handler*"

#~ msgid ""
#~ "The name set in `javax.inject.Named` of a bean that implements `io.smallrye.reactive.messaging.kafka.DeserializationFailureHandler`. If set, deserialization failure happening when deserializing values are delegated to this handler which may provide a fallback value.\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "`io.smallrye.reactive.messaging.kafka.DeserializationFailureHandler` を実装するBeanの `javax.inject.Named` で設定された名前です。設定されている場合、値のデシリアライズがこのハンドラに委ねられているときにデシリアライズの失敗が起こり、フォールバック値が提供されることがあります。\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "*graceful-shutdown*"
#~ msgstr "*graceful-shutdown*"

#~ msgid ""
#~ "Whether or not a graceful shutdown should be attempted when the application terminates.\n"
#~ "\n"
#~ "Type: _boolean_"
#~ msgstr ""
#~ "アプリケーションの終了時に、グレースフルシャットダウンを行うかどうか。\n"
#~ "\n"
#~ "Type: _boolean_"

#~ msgid "Outgoing Attributes of the 'smallrye-kafka' connector"
#~ msgstr "'smallrye-kafka' connectorのoutgoing 属性"

#~ msgid "*acks*"
#~ msgstr "*acks*"

#~ msgid ""
#~ "The number of acknowledgments the producer requires the leader to have received before considering a request complete. This controls the durability of records that are sent. Accepted values are: 0, 1, all\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "リクエストが完了したとみなす前に、プロデューサーがリーダーに受信を要求する確認応答の数。これは、送信されるレコードの耐久性を制御します。許容される値は0、1、all\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "*buffer.memory*"
#~ msgstr "*buffer.memory*"

#~ msgid ""
#~ "The total bytes of memory the producer can use to buffer records waiting to be sent to the server.\n"
#~ "\n"
#~ "Type: _long_"
#~ msgstr ""
#~ "サーバーへの送信待ちのレコードをバッファリングするために、プロデューサーが使用できるメモリの総バイト数。\n"
#~ "\n"
#~ "Type: _long_"

#~ msgid "*close-timeout*"
#~ msgstr "*close-timeout*"

#~ msgid ""
#~ "*cloud-events-data-content-type*\n"
#~ "\n"
#~ "_(cloud-events-default-data-content-type)_"
#~ msgstr ""
#~ "*cloud-events-data-content-type*\n"
#~ "\n"
#~ "_(cloud-events-default-data-content-type)_"

#~ msgid ""
#~ "Configure the default `datacontenttype` attribute of the outgoing Cloud Event. Requires `cloud-events` to be set to `true`. This value is used if the message does not configure the `datacontenttype` attribute itself\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "outgoing Cloud Eventのデフォルトの `datacontenttype` 属性を設定します。 `cloud-events` に `true` を設定する必要があります。この値は、メッセージが `datacontenttype` 属性を設定していない場合に使用されます。\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid ""
#~ "*cloud-events-data-schema*\n"
#~ "\n"
#~ "_(cloud-events-default-data-schema)_"
#~ msgstr ""
#~ "*cloud-events-data-schema*\n"
#~ "\n"
#~ "_(cloud-events-default-data-schema)_"

#~ msgid ""
#~ "Configure the default `dataschema` attribute of the outgoing Cloud Event. Requires `cloud-events` to be set to `true`. This value is used if the message does not configure the `dataschema` attribute itself\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "outgoing Cloud Eventのデフォルトの `dataschema` 属性を設定します。 `cloud-events` に `true` を設定する必要があります。この値は、メッセージが `dataschema` 属性を設定していない場合に使用されます。\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid ""
#~ "*cloud-events-insert-timestamp*\n"
#~ "\n"
#~ "_(cloud-events-default-timestamp)_"
#~ msgstr ""
#~ "*cloud-events-insert-timestamp*\n"
#~ "\n"
#~ "_(cloud-events-default-timestamp)_"

#~ msgid ""
#~ "Whether or not the connector should insert automatically the `time` attribute` into the outgoing Cloud Event. Requires `cloud-events` to be set to `true`. This value is used if the message does not configure the `time` attribute itself\n"
#~ "\n"
#~ "Type: _boolean_"
#~ msgstr ""
#~ "コネクタが、outgoing Cloud Eventに `time` 属性` を自動的に挿入するかどうかを指定します。 `cloud-events` に `true` を設定する必要があります。この値は、メッセージ自身が `time` 属性を構成していない場合に使用されます。\n"
#~ "\n"
#~ "Type: _boolean_"

#~ msgid "*cloud-events-mode*"
#~ msgstr "*cloud-events-mode*"

#~ msgid ""
#~ "The Cloud Event mode (`structured` or `binary` (default)). Indicates how are written the cloud events in the outgoing record\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "Cloud Eventのモード（ `structured` または `binary` （デフォルト））。outgoing レコードにCloud Eventをどのように書き込むかを示します\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "`binary`"
#~ msgstr "`binary`"

#~ msgid ""
#~ "*cloud-events-source*\n"
#~ "\n"
#~ "_(cloud-events-default-source)_"
#~ msgstr ""
#~ "*cloud-events-source*\n"
#~ "\n"
#~ "_(cloud-events-default-source)_"

#~ msgid ""
#~ "Configure the default `source` attribute of the outgoing Cloud Event. Requires `cloud-events` to be set to `true`. This value is used if the message does not configure the `source` attribute itself\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "outgoing Cloud Eventのデフォルトの `source` 属性を設定します。 `cloud-events` に `true` を設定する必要があります。この値は、メッセージが `source` 属性を設定していない場合に使用されます。\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid ""
#~ "*cloud-events-subject*\n"
#~ "\n"
#~ "_(cloud-events-default-subject)_"
#~ msgstr ""
#~ "*cloud-events-subject*\n"
#~ "\n"
#~ "_(cloud-events-default-subject)_"

#~ msgid ""
#~ "Configure the default `subject` attribute of the outgoing Cloud Event. Requires `cloud-events` to be set to `true`. This value is used if the message does not configure the `subject` attribute itself\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "outgoing Cloud Eventのデフォルトの `subject` 属性を設定します。 `cloud-events` に `true` を設定する必要があります。この値は、メッセージが `subject` 属性を設定していない場合に使用されます。\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid ""
#~ "*cloud-events-type*\n"
#~ "\n"
#~ "_(cloud-events-default-type)_"
#~ msgstr ""
#~ "*cloud-events-type*\n"
#~ "\n"
#~ "_(cloud-events-default-type)_"

#~ msgid ""
#~ "Configure the default `type` attribute of the outgoing Cloud Event. Requires `cloud-events` to be set to `true`. This value is used if the message does not configure the `type` attribute itself\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "outgoing Cloud Eventのデフォルトの `type` 属性を設定します。 `cloud-events` に `true` を設定する必要があります。この値は、メッセージが `type` 属性を設定していない場合に使用されます。\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "*key*"
#~ msgstr "*key*"

#~ msgid ""
#~ "A key to used when writing the record\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "レコードを書くときに使うキー\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "*key.serializer*"
#~ msgstr "*key.serializer*"

#~ msgid ""
#~ "The serializer classname used to serialize the record's key\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "レコードのキーをシリアル化するために使用されるシリアライザのクラス名\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "`org.apache.kafka.common.serialization.StringSerializer`"
#~ msgstr "`org.apache.kafka.common.serialization.StringSerializer`"

#~ msgid "*max-inflight-messages*"
#~ msgstr "*max-inflight-messages*"

#~ msgid ""
#~ "The maximum number of messages to be written to Kafka concurrently. It limits the number of messages waiting to be written and acknowledged by the broker. You can set this attribute to `0` remove the limit\n"
#~ "\n"
#~ "Type: _long_"
#~ msgstr ""
#~ "Kafkaに同時に書き込まれるメッセージの最大数。ブローカーが書き込みと確認を待っているメッセージの数を制限します。この属性を `0` に設定することで、制限を取り除くことができます。\n"
#~ "\n"
#~ "Type: _long_"

#~ msgid "*merge*"
#~ msgstr "*merge*"

#~ msgid ""
#~ "Whether the connector should allow multiple upstreams\n"
#~ "\n"
#~ "Type: _boolean_"
#~ msgstr ""
#~ "コネクタが複数のアップストリームを許可するかどうか\n"
#~ "\n"
#~ "Type: _boolean_"

#~ msgid "*partition*"
#~ msgstr "*partition*"

#~ msgid ""
#~ "The target partition id. -1 to let the client determine the partition\n"
#~ "\n"
#~ "Type: _int_"
#~ msgstr ""
#~ "ターゲットのパーティションID。-1の場合、クライアントがパーティションを決定\n"
#~ "\n"
#~ "Type: _int_"

#~ msgid "*retries*"
#~ msgstr "*retries*"

#~ msgid ""
#~ "Setting a value greater than zero will cause the client to resend any record whose send fails with a potentially transient error.\n"
#~ "\n"
#~ "Type: _long_"
#~ msgstr ""
#~ "ゼロより大きい値を設定すると、一時的なエラーで送信に失敗したレコードをクライアントが再送信する。\n"
#~ "\n"
#~ "Type: _long_"

#~ msgid "*value.serializer*"
#~ msgstr "*value.serializer*"

#~ msgid ""
#~ "The serializer classname used to serialize the payload\n"
#~ "\n"
#~ "Type: _string_"
#~ msgstr ""
#~ "ペイロードのシリアライズに使用されるシリアライザーのクラス名\n"
#~ "\n"
#~ "Type: _string_"

#~ msgid "*waitForWriteCompletion*"
#~ msgstr "*waitForWriteCompletion*"

#~ msgid ""
#~ "Whether the client waits for Kafka to acknowledge the written record before acknowledging the message\n"
#~ "\n"
#~ "Type: _boolean_"
#~ msgstr ""
#~ "クライアントがメッセージを確認する前に、Kafkaが書き込まれたレコードを確認するのを待つかどうか\n"
#~ "\n"
#~ "Type: _boolean_"

#~ msgid "OAuth authentication works for both JVM and native modes."
#~ msgstr "OAuth 認証は JVM とネイティブモードの両方で動作します。"

#~ msgid "Prerequisites"
#~ msgstr "前提条件"

#~ msgid "To complete this guide, you need:"
#~ msgstr "このガイドを完成させるには、以下が必要です:"

#~ msgid "an IDE"
#~ msgstr "IDE"

#~ msgid "Apache Maven {maven-version}"
#~ msgstr "Apache Maven {maven-version}"

#~ msgid "A running Kafka cluster, or Docker Compose to start a development cluster"
#~ msgstr "実行中の Kafka クラスター、または開発クラスターを開始するための Docker Compose"

#~ msgid "GraalVM installed if you want to run in native mode."
#~ msgstr "ネイティブモードで実行する場合は、GraalVM がインストールされていること"

#~ msgid "Architecture"
#~ msgstr "アーキテクチャ"

#~ msgid "In this guide, we are going to generate (random) prices in one component.  These prices are written in a Kafka topic (`prices`).  A second component reads from the `prices` Kafka topic and apply some magic conversion to the price.  The result is sent to an in-memory stream consumed by a JAX-RS resource.  The data is sent to a browser using server-sent events."
#~ msgstr "このガイドでは、1 つのコンポーネントでランダムな価格 (price) を生成します。これらの価格は、Kafka トピック (`prices`) に書かれています。2 番目のコンポーネントは `prices` Kafka トピックから読み込み、この価格に変換を適用します。その結果は、JAX-RS リソースによって消費されるインメモリーストリームに送られます。データは、サーバーから送信されたイベントを使用してブラウザーに送信されます。"

#~ msgid "kafka-guide-architecture.png"
#~ msgstr "kafka-guide-architecture.png"

#~ msgid "We recommend that you follow the instructions in the next sections and create the application step by step.  However, you can go right to the completed example."
#~ msgstr "次の章で紹介する手順に沿って、ステップを踏んでアプリを作成することをお勧めします。ただし、完成した例にそのまま進んでも構いません。"

#~ msgid "Clone the Git repository: `git clone {quickstarts-clone-url}`, or download an {quickstarts-archive-url}[archive]."
#~ msgstr "Gitレポジトリをクローンするか `git clone {quickstarts-clone-url}` 、 {quickstarts-archive-url}[アーカイブ] をダウンロードします。"

#~ msgid "The solution is located in the `kafka-quickstart` {quickstarts-tree-url}/kafka-quickstart[directory]."
#~ msgstr "このソリューションは `kafka-quickstart` {quickstarts-tree-url}/kafka-quickstart[ディレクトリ] にあります。"

#~ msgid "First, we need a new project. Create a new project with the following command:"
#~ msgstr "まず、新しいプロジェクトが必要です。以下のコマンドで新規プロジェクトを作成します。"

#, fuzzy
#~| msgid ""
#~| "mvn io.quarkus:quarkus-maven-plugin:{quarkus-version}:create \\\n"
#~| "    -DprojectGroupId=org.acme \\\n"
#~| "    -DprojectArtifactId=kafka-quickstart \\\n"
#~| "    -DclassName=\"org.acme.kafka.PriceResource\" \\\n"
#~| "    -Dpath=\"/prices\" \\\n"
#~| "    -Dextensions=\"resteasy,smallrye-reactive-messaging-kafka\"\n"
#~| "cd kafka-quickstart\n"
#~ msgid ""
#~ "mvn io.quarkus:quarkus-maven-plugin:{quarkus-version}:create \\\n"
#~ "    -DprojectGroupId=org.acme \\\n"
#~ "    -DprojectArtifactId=kafka-quickstart \\\n"
#~ "    -DclassName=\"org.acme.kafka.PriceResource\" \\\n"
#~ "    -Dpath=\"/prices\" \\\n"
#~ "    -Dextensions=\"resteasy-reactive,smallrye-reactive-messaging-kafka\"\n"
#~ "cd kafka-quickstart\n"
#~ msgstr ""
#~ "mvn io.quarkus:quarkus-maven-plugin:{quarkus-version}:create \\\n"
#~ "    -DprojectGroupId=org.acme \\\n"
#~ "    -DprojectArtifactId=kafka-quickstart \\\n"
#~ "    -DclassName=\"org.acme.kafka.PriceResource\" \\\n"
#~ "    -Dpath=\"/prices\" \\\n"
#~ "    -Dextensions=\"resteasy,smallrye-reactive-messaging-kafka\"\n"
#~ "cd kafka-quickstart\n"

#~ msgid "This command generates a Maven project, importing the Reactive Messaging and Kafka connector extensions."
#~ msgstr "このコマンドは、Reactive Messaging と Kafka コネクタエクステンションをインポートして Maven プロジェクトを生成します。"

#, fuzzy
#~| msgid "services:\n"
#~ msgid "Dev Services"
#~ msgstr "services:\n"

#~ msgid "The price generator"
#~ msgstr "価格ジェネレーター"

#~ msgid "Create the `src/main/java/org/acme/kafka/PriceGenerator.java` file, with the following content:"
#~ msgstr "以下の内容の `src/main/java/org/acme/kafka/PriceGenerator.java` ファイルを作成します。"

#~ msgid ""
#~ "/**\n"
#~ " * A bean producing random prices every 5 seconds.\n"
#~ " * The prices are written to a Kafka topic (prices). The Kafka configuration is specified in the application configuration.\n"
#~ " */\n"
#~ "@ApplicationScoped\n"
#~ "public class PriceGenerator {\n"
#~ msgstr ""
#~ "/**\n"
#~ " * A bean producing random prices every 5 seconds.\n"
#~ " * The prices are written to a Kafka topic (prices). The Kafka configuration is specified in the application configuration.\n"
#~ " */\n"
#~ "@ApplicationScoped\n"
#~ "public class PriceGenerator {\n"

#~ msgid "Instruct Reactive Messaging to dispatch the items from returned stream to `generated-price`."
#~ msgstr "返されたストリームから `generated-price` にアイテムをディスパッチするように Reactive Messaging に指示します。"

#~ msgid "The method returns a Mutiny _stream_ (`Multi`) emitting a random _price_ every 5 seconds."
#~ msgstr "このメソッドは、5 秒ごとにランダムな _価格_ を生成する Mutiny _ストリーム_ (`Multi`) を返します。"

#~ msgid "The method returns a _Reactive Stream_. The generated items are sent to the stream named `generated-price`.  This stream is mapped to Kafka using the `application.properties` file that we will create soon."
#~ msgstr "このメソッドは、_Reactive Stream_ を返します。生成されたアイテムは `generated-price` という名前のストリームに送られます。このストリームは、次に作成する `application.properties` ファイルを使用して Kafka にマッピングされます。"

#~ msgid "The price converter"
#~ msgstr "価格 (price) コンバーター"

#~ msgid "The price converter reads the prices from Kafka, and transforms them.  Create the `src/main/java/org/acme/kafka/PriceConverter.java` file with the following content:"
#~ msgstr "価格コンバーターは、Kafka から価格を読み込んで変換します。以下の内容の `src/main/java/org/acme/kafka/PriceConverter.java` ファイルを作成します。"

#~ msgid ""
#~ "/**\n"
#~ " * A bean consuming data from the \"prices\" Kafka topic and applying some conversion.\n"
#~ " * The result is pushed to the \"my-data-stream\" stream which is an in-memory stream.\n"
#~ " */\n"
#~ "@ApplicationScoped\n"
#~ "public class PriceConverter {\n"
#~ msgstr ""
#~ "/**\n"
#~ " * A bean consuming data from the \"prices\" Kafka topic and applying some conversion.\n"
#~ " * The result is pushed to the \"my-data-stream\" stream which is an in-memory stream.\n"
#~ " */\n"
#~ "@ApplicationScoped\n"
#~ "public class PriceConverter {\n"

#, fuzzy
#~| msgid ""
#~| "    @Incoming(\"prices\")                                     // <1>\n"
#~| "    @Outgoing(\"my-data-stream\")                             // <2>\n"
#~| "    @Broadcast                                              // <3>\n"
#~| "    @Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING) // <4>\n"
#~| "    public double process(int priceInUsd) {\n"
#~| "        return priceInUsd * CONVERSION_RATE;\n"
#~| "    }\n"
#~ msgid ""
#~ "    @Incoming(\"prices\")                                     // <1>\n"
#~ "    @Outgoing(\"my-data-stream\")                             // <2>\n"
#~ "    public double process(int priceInUsd) {\n"
#~ "        return priceInUsd * CONVERSION_RATE;\n"
#~ "    }\n"
#~ msgstr ""
#~ "    @Incoming(\"prices\")                                     // <1>\n"
#~ "    @Outgoing(\"my-data-stream\")                             // <2>\n"
#~ "    @Broadcast                                              // <3>\n"
#~ "    @Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING) // <4>\n"
#~ "    public double process(int priceInUsd) {\n"
#~ "        return priceInUsd * CONVERSION_RATE;\n"
#~ "    }\n"

#~ msgid "Indicates that the method consumes the items from the `prices` topic"
#~ msgstr "このメソッドが `prices` トピックのアイテムを消費することを示します。"

#~ msgid "Indicates that the objects returned by the method are sent to the `my-data-stream` stream"
#~ msgstr "このメソッドによって返されたオブジェクトが `my-data-stream` ストリームに送られることを示します。"

#~ msgid "The `process` method is called for every Kafka _record_ from the `prices` topic (configured in the application configuration).  Every result is sent to the `my-data-stream` in-memory stream."
#~ msgstr "`process` メソッドは、`prices` トピック (アプリケーション設定の中で設定) からの Kafka _レコード_ ごとに呼び出されます。すべての結果は `my-data-stream` インメモリーストリームに送信されます。"

#~ msgid "The price resource"
#~ msgstr "価格リソース"

#~ msgid "Finally, let's bind our stream to a JAX-RS resource.  Creates the `src/main/java/org/acme/kafka/PriceResource.java` file with the following content:"
#~ msgstr "最後に、ストリームを JAX-RSリソース にバインドしてみましょう。以下の内容の `src/main/java/org/acme/kafka/PriceResource.java` ファイルを作成します。"

#~ msgid ""
#~ "import io.smallrye.reactive.messaging.annotations.Channel;\n"
#~ "import org.reactivestreams.Publisher;\n"
#~ msgstr ""
#~ "import io.smallrye.reactive.messaging.annotations.Channel;\n"
#~ "import org.reactivestreams.Publisher;\n"

#~ msgid ""
#~ "/**\n"
#~ " * A simple resource retrieving the in-memory \"my-data-stream\" and sending the items as server-sent events.\n"
#~ " */\n"
#~ "@Path(\"/prices\")\n"
#~ "public class PriceResource {\n"
#~ msgstr ""
#~ "/**\n"
#~ " * A simple resource retrieving the in-memory \"my-data-stream\" and sending the items as server-sent events.\n"
#~ " */\n"
#~ "@Path(\"/prices\")\n"
#~ "public class PriceResource {\n"

#, fuzzy
#~| msgid ""
#~| "    @Inject\n"
#~| "    @Channel(\"my-data-stream\") Publisher<Double> prices; // <1>\n"
#~ msgid ""
#~ "    @Inject\n"
#~ "    @Channel(\"my-data-stream\")\n"
#~ "    Publisher<Double> prices; // <1>\n"
#~ msgstr ""
#~ "    @Inject\n"
#~ "    @Channel(\"my-data-stream\") Publisher<Double> prices; // <1>\n"

#~ msgid "Injects the `my-data-stream` channel using the `@Channel` qualifier"
#~ msgstr "`@Channel` の修飾子を使って `my-data-stream` チャンネルを注入します。"

#~ msgid "Indicates that the content is sent using `Server Sent Events`"
#~ msgstr "`Server Sent Events` を使用してコンテンツが送信されたことを示します。"

#~ msgid "Indicates that the data contained within the server sent events is of type `text/plain`"
#~ msgstr "サーバーから送信されたイベントに含まれるデータのタイプが `text/plain` であることを示します。"

#~ msgid "Returns the stream (_Reactive Stream_)"
#~ msgstr "ストリーム (_Reactive Stream_) を返します。"

#~ msgid "We need to configure the Kafka connector. This is done in the `application.properties` file.  The keys are structured as follows:"
#~ msgstr "Kafka コネクターを設定する必要があります。これは `application.properties` ファイルで行います。このキーは以下のような構造になっています。"

#~ msgid "`mp.messaging.[outgoing|incoming].{channel-name}.property=value`"
#~ msgstr "`mp.messaging.[outgoing|incoming].{channel-name}.property=value`"

#~ msgid "The `channel-name` segment must match the value set in the `@Incoming` and `@Outgoing` annotation:"
#~ msgstr "`channel-name` セグメントは、 `@Incoming` および `@Outgoing` アノテーションで設定された値と一致する必要があります。"

#~ msgid "`generated-price` -> sink in which we write the prices"
#~ msgstr "`generated-price` -> sink (価格の書き込み先)"

#~ msgid "`prices` -> source in which we read the prices"
#~ msgstr "`prices` -> source (価格の読み取り先)"

#~ msgid ""
#~ "# Configure the Kafka sink (we write to it)\n"
#~ "mp.messaging.outgoing.generated-price.connector=smallrye-kafka\n"
#~ "mp.messaging.outgoing.generated-price.topic=prices\n"
#~ "mp.messaging.outgoing.generated-price.value.serializer=org.apache.kafka.common.serialization.IntegerSerializer\n"
#~ msgstr ""
#~ "# Configure the Kafka sink (we write to it)\n"
#~ "mp.messaging.outgoing.generated-price.connector=smallrye-kafka\n"
#~ "mp.messaging.outgoing.generated-price.topic=prices\n"
#~ "mp.messaging.outgoing.generated-price.value.serializer=org.apache.kafka.common.serialization.IntegerSerializer\n"

#~ msgid "More details about this configuration is available on the https://kafka.apache.org/documentation/#producerconfigs[Producer configuration] and https://kafka.apache.org/documentation/#consumerconfigs[Consumer configuration] section from the Kafka documentation. These properties are configured with the prefix `kafka`."
#~ msgstr "この設定の詳細は、Kafka ドキュメントの link:https://kafka.apache.org/documentation/#producerconfigs[Producer 設定] と link:https://kafka.apache.org/documentation/#consumerconfigs[Consumer 設定] のセクションを参照してください。これらのプロパティは、`kafka` という接頭辞で設定されます。"

#~ msgid "What about `my-data-stream`? This is an in-memory stream, not connected to a message broker."
#~ msgstr "`my-data-stream` はどうでしょうか? これはインメモリストリームであり、メッセージブローカーには接続されていません。"

#~ msgid "Final touch, the HTML page reading the converted prices using SSE."
#~ msgstr "最後に、SSE を使って変換された価格を読み込む HTML ページです。"

#~ msgid "Create the `src/main/resources/META-INF/resources/prices.html` file, with the following content:"
#~ msgstr "以下の内容の `src/main/resources/META-INF/resources/prices.html` ファイルを作成します。"

#~ msgid ""
#~ "<!DOCTYPE html>\n"
#~ "<html lang=\"en\">\n"
#~ "<head>\n"
#~ "    <meta charset=\"UTF-8\">\n"
#~ "    <title>Prices</title>\n"
#~ msgstr ""
#~ "<!DOCTYPE html>\n"
#~ "<html lang=\"en\">\n"
#~ "<head>\n"
#~ "    <meta charset=\"UTF-8\">\n"
#~ "    <title>Prices</title>\n"

#~ msgid ""
#~ "    <link rel=\"stylesheet\" type=\"text/css\"\n"
#~ "          href=\"https://cdnjs.cloudflare.com/ajax/libs/patternfly/3.24.0/css/patternfly.min.css\">\n"
#~ "    <link rel=\"stylesheet\" type=\"text/css\"\n"
#~ "          href=\"https://cdnjs.cloudflare.com/ajax/libs/patternfly/3.24.0/css/patternfly-additions.min.css\">\n"
#~ "</head>\n"
#~ "<body>\n"
#~ "<div class=\"container\">\n"
#~ msgstr ""
#~ "    <link rel=\"stylesheet\" type=\"text/css\"\n"
#~ "          href=\"https://cdnjs.cloudflare.com/ajax/libs/patternfly/3.24.0/css/patternfly.min.css\">\n"
#~ "    <link rel=\"stylesheet\" type=\"text/css\"\n"
#~ "          href=\"https://cdnjs.cloudflare.com/ajax/libs/patternfly/3.24.0/css/patternfly-additions.min.css\">\n"
#~ "</head>\n"
#~ "<body>\n"
#~ "<div class=\"container\">\n"

#~ msgid ""
#~ "    <h2>Last price</h2>\n"
#~ "    <div class=\"row\">\n"
#~ "    <p class=\"col-md-12\">The last price is <strong><span id=\"content\">N/A</span>&nbsp;&euro;</strong>.</p>\n"
#~ "    </div>\n"
#~ "</div>\n"
#~ "</body>\n"
#~ "<script src=\"https://code.jquery.com/jquery-3.3.1.min.js\"></script>\n"
#~ "<script>\n"
#~ "    var source = new EventSource(\"/prices/stream\");\n"
#~ "    source.onmessage = function (event) {\n"
#~ "        document.getElementById(\"content\").innerHTML = event.data;\n"
#~ "    };\n"
#~ "</script>\n"
#~ "</html>\n"
#~ msgstr ""
#~ "    <h2>Last price</h2>\n"
#~ "    <div class=\"row\">\n"
#~ "    <p class=\"col-md-12\">The last price is <strong><span id=\"content\">N/A</span>&nbsp;&euro;</strong>.</p>\n"
#~ "    </div>\n"
#~ "</div>\n"
#~ "</body>\n"
#~ "<script src=\"https://code.jquery.com/jquery-3.3.1.min.js\"></script>\n"
#~ "<script>\n"
#~ "    var source = new EventSource(\"/prices/stream\");\n"
#~ "    source.onmessage = function (event) {\n"
#~ "        document.getElementById(\"content\").innerHTML = event.data;\n"
#~ "    };\n"
#~ "</script>\n"
#~ "</html>\n"

#~ msgid "Nothing spectacular here. On each received price, it updates the page."
#~ msgstr "特に目を見張るようなものは何もありません。受信した価格ごとに、ページが更新されます。"

#~ msgid "Get it running"
#~ msgstr "実行"

#~ msgid "./mvnw quarkus:dev\n"
#~ msgstr "./mvnw quarkus:dev\n"

#~ msgid "Open `http://localhost:8080/prices.html` in your browser."
#~ msgstr "ブラウザーで `http://localhost:8080/prices.html` を開いてください。"

#, fuzzy
#~| msgid "Running Native"
#~ msgid "Running in JVM or Native mode"
#~ msgstr "ネイティブ実行"

#, fuzzy
#~| msgid "Then, we need a Kafka cluster.  You can follow the instructions from the https://kafka.apache.org/quickstart[Apache Kafka web site] or create a `docker-compose.yaml` file with the following content:"
#~ msgid "When not running in dev or test mode, you will need to start your Kafka broker.  You can follow the instructions from the https://kafka.apache.org/quickstart[Apache Kafka web site] or create a `docker-compose.yaml` file with the following content:"
#~ msgstr "次に、Kafka クラスターが必要です。 https://kafka.apache.org/quickstart[Apache Kafka の Web サイト] の指示に従うか、以下の内容の `docker-compose.yaml` ファイルを作成します。"

#~ msgid "version: '2'\n"
#~ msgstr "version: '2'\n"

#~ msgid "services:\n"
#~ msgstr "services:\n"

#, fuzzy
#~| msgid ""
#~| "  zookeeper:\n"
#~| "    image: strimzi/kafka:0.19.0-kafka-2.5.0\n"
#~| "    command: [\n"
#~| "      \"sh\", \"-c\",\n"
#~| "      \"bin/zookeeper-server-start.sh config/zookeeper.properties\"\n"
#~| "    ]\n"
#~| "    ports:\n"
#~| "      - \"2181:2181\"\n"
#~| "    environment:\n"
#~| "      LOG_DIR: /tmp/logs\n"
#~ msgid ""
#~ "  zookeeper:\n"
#~ "    image: quay.io/strimzi/kafka:0.23.0-kafka-2.8.0\n"
#~ "    command: [\n"
#~ "      \"sh\", \"-c\",\n"
#~ "      \"bin/zookeeper-server-start.sh config/zookeeper.properties\"\n"
#~ "    ]\n"
#~ "    ports:\n"
#~ "      - \"2181:2181\"\n"
#~ "    environment:\n"
#~ "      LOG_DIR: /tmp/logs\n"
#~ msgstr ""
#~ "  zookeeper:\n"
#~ "    image: strimzi/kafka:0.19.0-kafka-2.5.0\n"
#~ "    command: [\n"
#~ "      \"sh\", \"-c\",\n"
#~ "      \"bin/zookeeper-server-start.sh config/zookeeper.properties\"\n"
#~ "    ]\n"
#~ "    ports:\n"
#~ "      - \"2181:2181\"\n"
#~ "    environment:\n"
#~ "      LOG_DIR: /tmp/logs\n"

#, fuzzy
#~| msgid ""
#~| "  kafka:\n"
#~| "    image: strimzi/kafka:0.19.0-kafka-2.5.0\n"
#~| "    command: [\n"
#~| "      \"sh\", \"-c\",\n"
#~| "      \"bin/kafka-server-start.sh config/server.properties --override listeners=$${KAFKA_LISTENERS} --override advertised.listeners=$${KAFKA_ADVERTISED_LISTENERS} --override zookeeper.connect=$${KAFKA_ZOOKEEPER_CONNECT}\"\n"
#~| "    ]\n"
#~| "    depends_on:\n"
#~| "      - zookeeper\n"
#~| "    ports:\n"
#~| "      - \"9092:9092\"\n"
#~| "    environment:\n"
#~| "      LOG_DIR: \"/tmp/logs\"\n"
#~| "      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092\n"
#~| "      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092\n"
#~| "      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n"
#~ msgid ""
#~ "  kafka:\n"
#~ "    image: quay.io/strimzi/kafka:0.23.0-kafka-2.8.0\n"
#~ "    command: [\n"
#~ "      \"sh\", \"-c\",\n"
#~ "      \"bin/kafka-server-start.sh config/server.properties --override listeners=$${KAFKA_LISTENERS} --override advertised.listeners=$${KAFKA_ADVERTISED_LISTENERS} --override zookeeper.connect=$${KAFKA_ZOOKEEPER_CONNECT}\"\n"
#~ "    ]\n"
#~ "    depends_on:\n"
#~ "      - zookeeper\n"
#~ "    ports:\n"
#~ "      - \"9092:9092\"\n"
#~ "    environment:\n"
#~ "      LOG_DIR: \"/tmp/logs\"\n"
#~ "      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092\n"
#~ "      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092\n"
#~ "      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n"
#~ msgstr ""
#~ "  kafka:\n"
#~ "    image: strimzi/kafka:0.19.0-kafka-2.5.0\n"
#~ "    command: [\n"
#~ "      \"sh\", \"-c\",\n"
#~ "      \"bin/kafka-server-start.sh config/server.properties --override listeners=$${KAFKA_LISTENERS} --override advertised.listeners=$${KAFKA_ADVERTISED_LISTENERS} --override zookeeper.connect=$${KAFKA_ZOOKEEPER_CONNECT}\"\n"
#~ "    ]\n"
#~ "    depends_on:\n"
#~ "      - zookeeper\n"
#~ "    ports:\n"
#~ "      - \"9092:9092\"\n"
#~ "    environment:\n"
#~ "      LOG_DIR: \"/tmp/logs\"\n"
#~ "      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092\n"
#~ "      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092\n"
#~ "      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n"

#~ msgid "Once created, run `docker-compose up`."
#~ msgstr "作成したら、`docker-compose up` を実行します。"

#~ msgid "This is a development cluster, do not use in production."
#~ msgstr "これは開発クラスターであり、本番では使用しないでください。"

#, fuzzy
#~| msgid "You can build the native executable with:"
#~ msgid "You can build and run the application in JVM mode with:"
#~ msgstr "以下ででネイティブ実行ファイルをビルドすることができます。"

#, fuzzy
#~| msgid "You can build the native executable with:"
#~ msgid "You can build and run the native executable with:"
#~ msgstr "以下ででネイティブ実行ファイルをビルドすることができます。"

#~ msgid "Imperative usage"
#~ msgstr "命令的な使用法"

#~ msgid "First, you need to include the `quarkus-jackson` extension (if you already use the `quarkus-resteasy-jackson` extension, this is not needed)."
#~ msgstr "まず、`quarkus-jackson` のエクステンションを含める必要があります (すでに `quarkus-resteasy-jackson` のエクステンションを使用している場合は、これは必要ありません)。"

#~ msgid "Now, your Kafka messages will contain a Jackson serialized representation of your Fruit pojo."
#~ msgstr "これで、Kafka メッセージには、Fruit pojo の Jackson によるシリアライズ表現が含まれるようになります。"

#~ msgid "First, you need to include the `quarkus-jsonb` extension (if you already use the `quarkus-resteasy-jsonb` extension, this is not needed)."
#~ msgstr "まず、`quarkus-jsonb` のエクステンションを含める必要があります (すでに `quarkus-resteasy-jsonb` のエクステンションを使用している場合は不要です)。"

#~ msgid "If you want RESTEasy to send JSON Server-Sent Events, you need to use the `@SseElementType` annotation to define the content type of the events, as the method will be annotated with `@Produces(MediaType.SERVER_SENT_EVENTS)`."
#~ msgstr "RESTEasy で JSON Server-Sent Events を送信したい場合は、`@SseElementType` アノテーションを使用してイベントのコンテンツタイプを定義する必要があります。これは、このメソッドが `@Produces(MediaType.SERVER_SENT_EVENTS)` のアノテーションが付くためです。"

#~ msgid "The following example shows how to use SSE from a Kafka topic source."
#~ msgstr "次の例は、Kafka トピックソースから SSE を使用する方法を示しています。"

#~ msgid ""
#~ "    @GET\n"
#~ "    @Path(\"/stream\")\n"
#~ "    @Produces(MediaType.SERVER_SENT_EVENTS)\n"
#~ "    @SseElementType(MediaType.APPLICATION_JSON)\n"
#~ "    public Publisher<Fruit> stream() {\n"
#~ "        return fruits;\n"
#~ "    }\n"
#~ "}\n"
#~ msgstr ""
#~ "    @GET\n"
#~ "    @Path(\"/stream\")\n"
#~ "    @Produces(MediaType.SERVER_SENT_EVENTS)\n"
#~ "    @SseElementType(MediaType.APPLICATION_JSON)\n"
#~ "    public Publisher<Fruit> stream() {\n"
#~ "        return fruits;\n"
#~ "    }\n"
#~ "}\n"

#~ msgid "package org.acme.panache;\n"
#~ msgstr "package org.acme.panache;\n"

#~ msgid ""
#~ "import io.smallrye.reactive.messaging.annotations.Broadcast;\n"
#~ "import org.eclipse.microprofile.reactive.messaging.Acknowledgment;\n"
#~ "import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
#~ "import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
#~ msgstr ""
#~ "import io.smallrye.reactive.messaging.annotations.Broadcast;\n"
#~ "import org.eclipse.microprofile.reactive.messaging.Acknowledgment;\n"
#~ "import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
#~ "import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"

#~ msgid "Indicates that the item are dispatched to all _subscribers_"
#~ msgstr "アイテムがすべての _サブスクライバー_ に発送されていることを示します。"

#~ msgid "Make sure to acknowledge the incoming message"
#~ msgstr "incoming メッセージの受け取りを確認してください。"

#~ msgid "What is \"mp.messaging.incoming.prices.health-readiness-enabled=false\"?"
#~ msgstr "\"mp.messaging.incoming.prices.health-readiness-enabled=false\" とは何ですか？"

#~ msgid "The `health-readiness-enabled` disables the readiness health check.  By default, it verifies that there is an active connection with the broker.  In our case, the connection only happens when we get the first consumer.  This is because the stream is consumed as an SSE, waiting lazily for the first connection to trigger the whole stream.  So, if you are running in an environment only routing traffic to containers that are _ready_ (such as Kubernetes), it would not send traffic to your application, which, as a consequence, will never connect to Kafka and pass the readiness check."
#~ msgstr "`health-readiness-enabled` は、Readinessヘルスチェックを無効にします。デフォルトでは、ブローカーとのアクティブな接続があるかどうかを検証します。今回のケースでは、最初のコンシューマを取得したときにのみ接続が発生します。これは、ストリームがSSEとして消費され、最初の接続がストリーム全体のトリガーとなるのをのんびりと待っているからです。そのため、 _準備_ ができているコンテナにのみトラフィックをルーティングする環境（Kubernetesなど）で実行している場合、アプリケーションにトラフィックを送らないことになり、結果としてKafkaに接続してReadinessチェックを通過することはありません。"

#~ msgid "More details about health reporting is given in <<kafka-health-check>>."
#~ msgstr "ヘルスレポートについての詳細は、 <<kafka-health-check>>に記載されています。"

#~ msgid ""
#~ "# Configure the SmallRye Kafka connector\n"
#~ "kafka.bootstrap.servers=localhost:9092\n"
#~ msgstr ""
#~ "# Configure the SmallRye Kafka connector\n"
#~ "kafka.bootstrap.servers=localhost:9092\n"

#~ msgid "If you followed the instructions, you should have Kafka running.  Then, you just need to run the application using:"
#~ msgstr "指示に従えば、Kafka が起動しているはずです。あとは、以下でアプリケーションを実行するだけです。"

#~ msgid "If you started the Kafka broker with docker compose, stop it using `CTRL+C` followed by `docker-compose down`."
#~ msgstr "Kafka ブローカーを docker compose で起動した場合は、`CTRL+C` に続いて `docker-compose down` で停止します。"

#~ msgid "./mvnw package -Pnative\n"
#~ msgstr "./mvnw package -Pnative\n"
